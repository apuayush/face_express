{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/apuayush/face_express/blob/master/training.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "56zu04MAchOf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for mounting drive with google colabs\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIcp0a35KSHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnHOW57MKWV0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jsMmkQq0TD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1031205-20d2-4095-8057-ab36a878f06a"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  drive\tlogs\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AwcI6o1NkCAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time \n",
        "import os\n",
        "import cv2\n",
        "import datetime\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ep4jky9PJHZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reading data"
      ]
    },
    {
      "metadata": {
        "id": "Qz-FqetJmBTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('drive/fer2013.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvcWR4P4VMqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "542b68dd-86b9-4486-ac6d-4c07b57ef1a3"
      },
      "cell_type": "code",
      "source": [
        "data['Usage'].unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Training', 'PublicTest', 'PrivateTest'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "KLS-6PRJUbNQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_train = data.loc[data['Usage']=='Training']\n",
        "public_test = data.loc[data['Usage']=='PublicTest']\n",
        "private_test = data.loc[data['Usage']=='PrivateTest']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W94GR_DZmHXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b7340d6f-a27b-4dce-d55b-fda98870e710"
      },
      "cell_type": "code",
      "source": [
        "data_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "mbUnTOc_WCyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "bf1e42f9-f8a3-474d-a32e-4649f920a755"
      },
      "cell_type": "code",
      "source": [
        "public_test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28709</th>\n",
              "      <td>0</td>\n",
              "      <td>254 254 254 254 254 249 255 160 2 58 53 70 77 ...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28710</th>\n",
              "      <td>1</td>\n",
              "      <td>156 184 198 202 204 207 210 212 213 214 215 21...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28711</th>\n",
              "      <td>4</td>\n",
              "      <td>69 118 61 60 96 121 103 87 103 88 70 90 115 12...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28712</th>\n",
              "      <td>6</td>\n",
              "      <td>205 203 236 157 83 158 120 116 94 86 155 180 2...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28713</th>\n",
              "      <td>3</td>\n",
              "      <td>87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels       Usage\n",
              "28709        0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...  PublicTest\n",
              "28710        1  156 184 198 202 204 207 210 212 213 214 215 21...  PublicTest\n",
              "28711        4  69 118 61 60 96 121 103 87 103 88 70 90 115 12...  PublicTest\n",
              "28712        6  205 203 236 157 83 158 120 116 94 86 155 180 2...  PublicTest\n",
              "28713        3  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...  PublicTest"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "BtpLXlF4WG0I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ad30d50d-9f8c-4db6-a6c7-9b58d337357b"
      },
      "cell_type": "code",
      "source": [
        "private_test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32298</th>\n",
              "      <td>0</td>\n",
              "      <td>170 118 101 88 88 75 78 82 66 74 68 59 63 64 6...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32299</th>\n",
              "      <td>5</td>\n",
              "      <td>7 5 8 6 7 3 2 6 5 4 4 5 7 5 5 5 6 7 7 7 10 10 ...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32300</th>\n",
              "      <td>6</td>\n",
              "      <td>232 240 241 239 237 235 246 117 24 24 22 13 12...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32301</th>\n",
              "      <td>4</td>\n",
              "      <td>200 197 149 139 156 89 111 58 62 95 113 117 11...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32302</th>\n",
              "      <td>2</td>\n",
              "      <td>40 28 33 56 45 33 31 78 152 194 200 186 196 20...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels        Usage\n",
              "32298        0  170 118 101 88 88 75 78 82 66 74 68 59 63 64 6...  PrivateTest\n",
              "32299        5  7 5 8 6 7 3 2 6 5 4 4 5 7 5 5 5 6 7 7 7 10 10 ...  PrivateTest\n",
              "32300        6  232 240 241 239 237 235 246 117 24 24 22 13 12...  PrivateTest\n",
              "32301        4  200 197 149 139 156 89 111 58 62 95 113 117 11...  PrivateTest\n",
              "32302        2  40 28 33 56 45 33 31 78 152 194 200 186 196 20...  PrivateTest"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "2gyerwiGNZ8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "606c42e0-ca1d-4484-977f-a9085596a7b3"
      },
      "cell_type": "code",
      "source": [
        "data_train.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>28709.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.317427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.876632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            emotion\n",
              "count  28709.000000\n",
              "mean       3.317427\n",
              "std        1.876632\n",
              "min        0.000000\n",
              "25%        2.000000\n",
              "50%        3.000000\n",
              "75%        5.000000\n",
              "max        6.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "dXhgd_VRK9mH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "k = data_train.iloc[1,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7musTnWRMMhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da74eece-23b5-4fc0-8a54-d4671368bc9f"
      },
      "cell_type": "code",
      "source": [
        "len(k.split())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "gXUbIpYURgAN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "## Transforming csv to understandable image data"
      ]
    },
    {
      "metadata": {
        "id": "lhU2G8EKOeHP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "data_train = shuffle(data_train)\n",
        "public_test = shuffle(public_test)\n",
        "private_test = shuffle(private_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVU6a7pnMT1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12c0c392-ef10-444b-f9c2-e9b9be26d495"
      },
      "cell_type": "code",
      "source": [
        "train = np.array(data_train.iloc[:,1])\n",
        "validation = np.array(private_test.iloc[:,1])\n",
        "test = np.array(public_test.iloc[:,1])\n",
        "print(train.shape, test.shape, validation.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709,) (3589,) (3589,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-KKN2c-lPv5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = train.reshape(28709,1)\n",
        "test = test.reshape(3589,1)\n",
        "validation = validation.reshape(3589,1)\n",
        "X_train_flip = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ll4rh-3ZP3np",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b236a105-f34a-45ad-92d3-6d768a2a65ec"
      },
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28709, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "e-n86LvepCPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_augmentation(img):\n",
        "  img = cv2.flip(img.reshape(48,48), 1)\n",
        "  return np.array(img.reshape(48,48,1)).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "74JKfL9yO981",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reform_data_aug(img_str):\n",
        "  t1 = img_str[0].split()\n",
        "  t2 = np.array(t1).astype(np.float32)\n",
        "  t3 = t2.reshape(48, 48, 1)\n",
        "\n",
        "  X_train_flip.append(data_augmentation(t3))\n",
        "  return t3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PY2eyjItszJi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reform_data(img_str):\n",
        "  t1 = img_str[0].split()\n",
        "  t2 = np.array(t1).astype(np.float32)\n",
        "  t3 = t2.reshape(48, 48, 1)\n",
        "  return t3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v-SVD4HjNwN7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_1 = np.apply_along_axis(reform_data_aug, 1, train)\n",
        "X_test = np.apply_along_axis(reform_data, 1, test)\n",
        "X_validation = np.apply_along_axis(reform_data, 1, validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQod7SNzsWK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5eeb4987-fc27-49d0-f765-c362c8958b70"
      },
      "cell_type": "code",
      "source": [
        "np.array(X_train_flip).shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28709, 48, 48, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "WZz2eBuiq1QX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7795a3c-07c7-4f31-9d92-99ecd0708a13"
      },
      "cell_type": "code",
      "source": [
        "X_train = np.array(list(X_train_1) + X_train_flip)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57418, 48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_ZEDOnwDNxLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a2a2fbdd-3b4e-48c5-e6f2-1f568b8460e6"
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape, X_validation.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57418, 48, 48, 1) (3589, 48, 48, 1) (3589, 48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VbThqV1cRZaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "2227dcb7-28be-4eb7-975f-0be737a4d85a"
      },
      "cell_type": "code",
      "source": [
        "# Sample image\n",
        "plt.imshow(X_train[0].reshape(48,48))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7550d475f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD6CAYAAACI7Fo9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wAu/FmPEDkcxAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f75511c27f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WYB7ls1PTmSe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalization "
      ]
    },
    {
      "metadata": {
        "id": "SlrUS2YXSi3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "X_validation = X_validation/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwsAGZnLT6LD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One Hot Encoding"
      ]
    },
    {
      "metadata": {
        "id": "DddjY8kpTpRH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_train = data_train['emotion']\n",
        "Y_test = public_test['emotion']\n",
        "Y_validation = private_test['emotion']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pqH6KdN9ZmaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4b2053f-4273-4369-e879-9634e1985ef5"
      },
      "cell_type": "code",
      "source": [
        "print(Y_train.shape, Y_test.shape, Y_validation.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709,) (3589,) (3589,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zvweNZgLZo4R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def onehot(Y, C):\n",
        "  Y = np.eye(C)[Y].T\n",
        "  return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VsNoXc5HbDHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c5c44f1-c71a-4418-ed57-ac25f3f0e753"
      },
      "cell_type": "code",
      "source": [
        "data['emotion'].unique()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 4, 6, 3, 5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "yNWyfJYNbMFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_test = onehot(Y_test, 7).T\n",
        "Y_train = onehot(Y_train, 7).T\n",
        "Y_valid = onehot(Y_validation, 7).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HLB4j6WbcWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c0e8c90-a8e5-44ce-9492-b451a254526c"
      },
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28709, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "0iMkGB1wtYNj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_train = np.array(list(Y_train) + list(Y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pw_OvfvF4rBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0fd7e21-7e40-4d5f-c827-7a3465512a14"
      },
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57418, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "h_86wLen4vJR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train = shuffle(X_train, Y_train, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJ2_D-9K69nZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de818ae1-6028-4c76-bff3-9a304a394f42"
      },
      "cell_type": "code",
      "source": [
        "print(X_validation.shape, Y_valid.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1) (3589, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GpkHLbumbdvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clear memory\n",
        "del data\n",
        "del data_train\n",
        "del public_test\n",
        "del private_test\n",
        "del Y_validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "00cI1F-aSFhF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Models\n",
        "Taking 3 - 4 models for ensemble voting"
      ]
    },
    {
      "metadata": {
        "id": "3o79vhYEYKiI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2fdc1b3-5c85-4705-f5a7-3a26c2e71f28"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_M_Ig2oSLY1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1-Basic 5 layer model"
      ]
    },
    {
      "metadata": {
        "id": "eKGfnDEiSNlh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "input_shape = (48, 48, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_aM9YHvESPbQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Model1(input_shape=(48,48,1)):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=input_shape, data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
        "  model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(2*2*2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(2*2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(num_labels, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zI99IQASU6t-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1213
        },
        "outputId": "489303ea-cd24-469d-f4a3-26ea3bde635e"
      },
      "cell_type": "code",
      "source": [
        "model1 = Model1()\n",
        "model1.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 5,905,863\n",
            "Trainable params: 5,902,151\n",
            "Non-trainable params: 3,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8piOth2iZGjD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8U4Oe6R5d95Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir='./logs')\n",
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(\"/drive\", monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QjWde_EayatC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.load_weights(\"drive/face_expr_model1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C3ganIoqepJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "a6cce23b-a54d-483a-9ba1-85a650ff6e31"
      },
      "cell_type": "code",
      "source": [
        "model1.fit(X_train,Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=300,\n",
        "          verbose=1,\n",
        "          validation_data=(X_validation, Y_valid),\n",
        "          shuffle=True,\n",
        "          callbacks=[lr_reducer, early_stopper, tensorboard, checkpointer])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 57418 samples, validate on 3589 samples\n",
            "Epoch 1/300\n",
            "43840/57418 [=====================>........] - ETA: 27s - loss: 0.3085 - acc: 0.8987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 120s 2ms/step - loss: 0.3182 - acc: 0.8963 - val_loss: 1.2731 - val_acc: 0.6709\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.27313, saving model to /drive\n",
            "Epoch 2/300\n",
            "17408/57418 [========>.....................] - ETA: 1:19 - loss: 0.3355 - acc: 0.8915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3466 - acc: 0.8868 - val_loss: 1.2974 - val_acc: 0.6489\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.27313\n",
            "Epoch 3/300\n",
            "10944/57418 [====>.........................] - ETA: 1:32 - loss: 0.3368 - acc: 0.8865"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3456 - acc: 0.8844 - val_loss: 1.3302 - val_acc: 0.6559\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.27313\n",
            "Epoch 4/300\n",
            " 8896/57418 [===>..........................] - ETA: 1:36 - loss: 0.3441 - acc: 0.8853"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3552 - acc: 0.8833 - val_loss: 1.2190 - val_acc: 0.6620\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.27313 to 1.21900, saving model to /drive\n",
            "Epoch 5/300\n",
            " 7488/57418 [==>...........................] - ETA: 1:40 - loss: 0.3480 - acc: 0.8868"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3649 - acc: 0.8793 - val_loss: 1.3062 - val_acc: 0.6601\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.21900\n",
            "Epoch 6/300\n",
            " 7872/57418 [===>..........................] - ETA: 1:39 - loss: 0.4933 - acc: 0.8368"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3878 - acc: 0.8713 - val_loss: 1.2542 - val_acc: 0.6704\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.21900\n",
            "Epoch 7/300\n",
            " 8000/57418 [===>..........................] - ETA: 1:38 - loss: 0.3756 - acc: 0.8776"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3630 - acc: 0.8800 - val_loss: 1.3386 - val_acc: 0.6592\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.21900\n",
            "Epoch 8/300\n",
            " 6144/57418 [==>...........................] - ETA: 1:42 - loss: 0.4050 - acc: 0.8674"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3581 - acc: 0.8812 - val_loss: 1.2405 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.21900\n",
            "Epoch 9/300\n",
            " 7424/57418 [==>...........................] - ETA: 1:40 - loss: 0.3625 - acc: 0.8836"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3454 - acc: 0.8872 - val_loss: 1.2977 - val_acc: 0.6565\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.21900\n",
            "Epoch 10/300\n",
            " 7808/57418 [===>..........................] - ETA: 1:39 - loss: 0.3410 - acc: 0.8922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3412 - acc: 0.8890 - val_loss: 1.3018 - val_acc: 0.6581\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.21900\n",
            "Epoch 11/300\n",
            " 6144/57418 [==>...........................] - ETA: 1:42 - loss: 0.3206 - acc: 0.8910"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3303 - acc: 0.8903 - val_loss: 1.2574 - val_acc: 0.6665\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.21900\n",
            "Epoch 12/300\n",
            " 7424/57418 [==>...........................] - ETA: 1:40 - loss: 0.3074 - acc: 0.8994"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3177 - acc: 0.8942 - val_loss: 1.3263 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.21900\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a489375f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "rXNlohhle1zS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.save_weights(\"drive/face_expr_model1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLtAOTy6wMeA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c19c29da-5ef9-4ac6-8fa6-f4c7554fd675"
      },
      "cell_type": "code",
      "source": [
        "model1.evaluate(X_test, Y_test, batch_size=batch_size)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3589/3589 [==============================] - 2s 695us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3717110243372415, 0.670660351076874]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "mmSMPa3hfV9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYA-f0zNlcsn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2- Model2 - https://arxiv.org/pdf/1706.01509"
      ]
    },
    {
      "metadata": {
        "id": "cWN5Pq1-lgi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Model2(input_shape=(48,48,1)):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(10, (5,5), activation='relu', kernel_regularizer=l2(0.01), input_shape=input_shape))\n",
        "  model.add(MaxPooling2D())\n",
        "#   model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(10, (5,5), activation='relu'))\n",
        "  model.add(MaxPooling2D())\n",
        "#   model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(10, (3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D()) \n",
        "#   model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_labels, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "39oaxtDKxcCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "c00dd971-3d2f-4ecc-fb1f-2e462526142e"
      },
      "cell_type": "code",
      "source": [
        "model2 = Model2()\n",
        "model2.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 44, 44, 10)        260       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 22, 22, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 18, 18, 10)        2510      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 7, 7, 10)          910       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               23296     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 60,775\n",
            "Trainable params: 60,775\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zpHBq76n6hJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_reducer2 = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
        "tensorboard2 = TensorBoard(log_dir='./logs')\n",
        "early_stopper2 = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
        "checkpointer2 = ModelCheckpoint(\"/drive\", monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MRGCpXAsxfv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRbbgsPExK8F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.load_weights(\"drive/face_expr_model2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gh4JqzcLxnLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20612
        },
        "outputId": "447bb2b8-0f2c-4328-8538-b2367dd9f169"
      },
      "cell_type": "code",
      "source": [
        "model2.fit(X_train,Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=500,\n",
        "          verbose=1,\n",
        "          validation_data=(X_validation, Y_valid),\n",
        "          shuffle=True,\n",
        "          callbacks=[lr_reducer2, tensorboard2, checkpointer2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 57418 samples, validate on 3589 samples\n",
            "Epoch 1/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0620 - acc: 0.5969 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 1.21309\n",
            "Epoch 2/500\n",
            "50816/57418 [=========================>....] - ETA: 1s - loss: 1.0611 - acc: 0.5987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0620 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.21309\n",
            "Epoch 3/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0606 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.21309\n",
            "Epoch 4/500\n",
            "18880/57418 [========>.....................] - ETA: 8s - loss: 1.0741 - acc: 0.5960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0644 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.426607435297324e-12.\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.21309\n",
            "Epoch 5/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0598 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.21309\n",
            "Epoch 6/500\n",
            " 2880/57418 [>.............................] - ETA: 12s - loss: 1.0792 - acc: 0.5938"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0603 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.21309\n",
            "Epoch 7/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0614 - acc: 0.5968 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.0839467698301484e-12.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.21309\n",
            "Epoch 8/500\n",
            " 9024/57418 [===>..........................] - ETA: 10s - loss: 1.0601 - acc: 0.5961"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0617 - acc: 0.5988 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.21309\n",
            "Epoch 9/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0618 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.21309\n",
            "Epoch 10/500\n",
            "11520/57418 [=====>........................] - ETA: 9s - loss: 1.0641 - acc: 0.5943 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0589 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.775552053815855e-12.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.21309\n",
            "Epoch 11/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0617 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.21309\n",
            "Epoch 12/500\n",
            " 1600/57418 [..............................] - ETA: 12s - loss: 1.0690 - acc: 0.5875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0611 - acc: 0.5998 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.21309\n",
            "Epoch 13/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0619 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.497996926496826e-12.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.21309\n",
            "Epoch 14/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0569 - acc: 0.6001"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0583 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.21309\n",
            "Epoch 15/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0562 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.21309\n",
            "Epoch 16/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0755 - acc: 0.5975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0635 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.248197331425339e-12.\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.21309\n",
            "Epoch 17/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0603 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.21309\n",
            "Epoch 18/500\n",
            " 1600/57418 [..............................] - ETA: 12s - loss: 1.0526 - acc: 0.6038"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0603 - acc: 0.6001 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.21309\n",
            "Epoch 19/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0589 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.023377559251527e-12.\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.21309\n",
            "Epoch 20/500\n",
            " 8192/57418 [===>..........................] - ETA: 10s - loss: 1.0488 - acc: 0.6052"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0579 - acc: 0.6012 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.21309\n",
            "Epoch 21/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0628 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.21309\n",
            "Epoch 22/500\n",
            "10944/57418 [====>.........................] - ETA: 10s - loss: 1.0598 - acc: 0.5960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0595 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.8210398033263743e-12.\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.21309\n",
            "Epoch 23/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0606 - acc: 0.5970 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.21309\n",
            "Epoch 24/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0411 - acc: 0.6064"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0586 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.21309\n",
            "Epoch 25/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0609 - acc: 0.5956 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.638935862025015e-12.\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.21309\n",
            "Epoch 26/500\n",
            " 8384/57418 [===>..........................] - ETA: 10s - loss: 1.0623 - acc: 0.5980"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0549 - acc: 0.5993 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.21309\n",
            "Epoch 27/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0571 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.21309\n",
            "Epoch 28/500\n",
            "11264/57418 [====>.........................] - ETA: 10s - loss: 1.0624 - acc: 0.6025"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0596 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.4750422563068744e-12.\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.21309\n",
            "Epoch 29/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0590 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.21309\n",
            "Epoch 30/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0670 - acc: 0.6034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0610 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.21309\n",
            "Epoch 31/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0624 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.3275380794652846e-12.\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.21309\n",
            "Epoch 32/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0440 - acc: 0.6077"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0570 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.21309\n",
            "Epoch 33/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0583 - acc: 0.6009 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.21309\n",
            "Epoch 34/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0417 - acc: 0.6051"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0596 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.1947843105500345e-12.\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.21309\n",
            "Epoch 35/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0629 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.21309\n",
            "Epoch 36/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0427 - acc: 0.5893"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0611 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.21309\n",
            "Epoch 37/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0628 - acc: 0.5965 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.0753058599793919e-12.\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.21309\n",
            "Epoch 38/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0696 - acc: 0.5921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0600 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.21309\n",
            "Epoch 39/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0613 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.21309\n",
            "Epoch 40/500\n",
            "11200/57418 [====>.........................] - ETA: 9s - loss: 1.0476 - acc: 0.6029 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0577 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.677752739814527e-13.\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.21309\n",
            "Epoch 41/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0596 - acc: 0.5972 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.21309\n",
            "Epoch 42/500\n",
            " 1600/57418 [..............................] - ETA: 12s - loss: 1.0802 - acc: 0.5988"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0598 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.21309\n",
            "Epoch 43/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0604 - acc: 0.5970 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 8.709977075520293e-13.\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.21309\n",
            "Epoch 44/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0722 - acc: 0.5962"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0629 - acc: 0.5972 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.21309\n",
            "Epoch 45/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0573 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.21309\n",
            "Epoch 46/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0446 - acc: 0.6083"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0620 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 7.838979465546459e-13.\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.21309\n",
            "Epoch 47/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0580 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.21309\n",
            "Epoch 48/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0603 - acc: 0.5908"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0615 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.21309\n",
            "Epoch 49/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0610 - acc: 0.5988 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 7.055081616570008e-13.\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.21309\n",
            "Epoch 50/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0677 - acc: 0.6035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0592 - acc: 0.6015 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.21309\n",
            "Epoch 51/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0586 - acc: 0.6004 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.21309\n",
            "Epoch 52/500\n",
            "11328/57418 [====>.........................] - ETA: 10s - loss: 1.0598 - acc: 0.5988"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0618 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 6.349573210967519e-13.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.21309\n",
            "Epoch 53/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0613 - acc: 0.5967 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.21309\n",
            "Epoch 54/500\n",
            " 1600/57418 [..............................] - ETA: 12s - loss: 1.0627 - acc: 0.5944"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0594 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.21309\n",
            "Epoch 55/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0597 - acc: 0.5965 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 5.714615792292571e-13.\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.21309\n",
            "Epoch 56/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0587 - acc: 0.6004"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0590 - acc: 0.5971 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.21309\n",
            "Epoch 57/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0598 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.21309\n",
            "Epoch 58/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0501 - acc: 0.6007"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0591 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 5.143154457008803e-13.\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.21309\n",
            "Epoch 59/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0619 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.21309\n",
            "Epoch 60/500\n",
            " 1344/57418 [..............................] - ETA: 11s - loss: 1.0469 - acc: 0.5885"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0585 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.21309\n",
            "Epoch 61/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0641 - acc: 0.5962 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 4.628838816151531e-13.\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 1.21309\n",
            "Epoch 62/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0435 - acc: 0.6070"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0609 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.21309\n",
            "Epoch 63/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0628 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.21309\n",
            "Epoch 64/500\n",
            "11264/57418 [====>.........................] - ETA: 10s - loss: 1.0670 - acc: 0.5945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0623 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 4.1659546905908895e-13.\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.21309\n",
            "Epoch 65/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0616 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.21309\n",
            "Epoch 66/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0881 - acc: 0.6039"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0613 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 1.21309\n",
            "Epoch 67/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0589 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 3.7493592215318006e-13.\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.21309\n",
            "Epoch 68/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0479 - acc: 0.6045"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0598 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.21309\n",
            "Epoch 69/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0613 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.21309\n",
            "Epoch 70/500\n",
            "11200/57418 [====>.........................] - ETA: 10s - loss: 1.0638 - acc: 0.5946"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0607 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 3.3744232993786204e-13.\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.21309\n",
            "Epoch 71/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0619 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.21309\n",
            "Epoch 72/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0578 - acc: 0.6124"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0627 - acc: 0.5968 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.21309\n",
            "Epoch 73/500\n",
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0589 - acc: 0.6006 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 3.036981067018954e-13.\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.21309\n",
            "Epoch 74/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0618 - acc: 0.5928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0586 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.21309\n",
            "Epoch 75/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0610 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.21309\n",
            "Epoch 76/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0621 - acc: 0.5913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0613 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 2.7332828383443144e-13.\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.21309\n",
            "Epoch 77/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0592 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.21309\n",
            "Epoch 78/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0542 - acc: 0.6029"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0575 - acc: 0.6003 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.21309\n",
            "Epoch 79/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0614 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 2.4599546032989804e-13.\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.21309\n",
            "Epoch 80/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0771 - acc: 0.5921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0597 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.21309\n",
            "Epoch 81/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0601 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.21309\n",
            "Epoch 82/500\n",
            "11328/57418 [====>.........................] - ETA: 9s - loss: 1.0405 - acc: 0.6054 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0569 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 2.213959240547278e-13.\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 1.21309\n",
            "Epoch 83/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0579 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.21309\n",
            "Epoch 84/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0850 - acc: 0.5975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0612 - acc: 0.6011 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.21309\n",
            "Epoch 85/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0598 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.9925633408870991e-13.\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.21309\n",
            "Epoch 86/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0593 - acc: 0.6007"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0588 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 1.21309\n",
            "Epoch 87/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0597 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 1.21309\n",
            "Epoch 88/500\n",
            "11328/57418 [====>.........................] - ETA: 10s - loss: 1.0434 - acc: 0.6047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0574 - acc: 0.6004 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.7933069580092915e-13.\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 1.21309\n",
            "Epoch 89/500\n",
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0583 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 1.21309\n",
            "Epoch 90/500\n",
            " 1344/57418 [..............................] - ETA: 11s - loss: 1.0532 - acc: 0.5997"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0575 - acc: 0.5966 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 1.21309\n",
            "Epoch 91/500\n",
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0589 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.6139762866029111e-13.\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 1.21309\n",
            "Epoch 92/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0633 - acc: 0.5949"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0640 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 1.21309\n",
            "Epoch 93/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0590 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 1.21309\n",
            "Epoch 94/500\n",
            "11136/57418 [====>.........................] - ETA: 10s - loss: 1.0591 - acc: 0.5989"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0604 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.4525786579426202e-13.\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 1.21309\n",
            "Epoch 95/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0578 - acc: 0.6012 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 1.21309\n",
            "Epoch 96/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0573 - acc: 0.5967"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0592 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 1.21309\n",
            "Epoch 97/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0609 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.3073208287401813e-13.\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 1.21309\n",
            "Epoch 98/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0476 - acc: 0.5963"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0605 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 1.21309\n",
            "Epoch 99/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0617 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 1.21309\n",
            "Epoch 100/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0552 - acc: 0.6028"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0576 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.1765887336688888e-13.\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 1.21309\n",
            "Epoch 101/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0585 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 1.21309\n",
            "Epoch 102/500\n",
            "  832/57418 [..............................] - ETA: 12s - loss: 1.0933 - acc: 0.5853"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0560 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 1.21309\n",
            "Epoch 103/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0627 - acc: 0.5967 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0589297993156277e-13.\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 1.21309\n",
            "Epoch 104/500\n",
            " 7872/57418 [===>..........................] - ETA: 10s - loss: 1.0590 - acc: 0.5922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0632 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 1.21309\n",
            "Epoch 105/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0608 - acc: 0.5999 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 1.21309\n",
            "Epoch 106/500\n",
            "10752/57418 [====>.........................] - ETA: 10s - loss: 1.0554 - acc: 0.6084"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0627 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00106: ReduceLROnPlateau reducing learning rate to 9.530368437786138e-14.\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 1.21309\n",
            "Epoch 107/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0605 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 1.21309\n",
            "Epoch 108/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0519 - acc: 0.6002"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0619 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 1.21309\n",
            "Epoch 109/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0610 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 8.577331350062036e-14.\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 1.21309\n",
            "Epoch 110/500\n",
            " 8192/57418 [===>..........................] - ETA: 10s - loss: 1.0623 - acc: 0.6002"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0610 - acc: 0.6010 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 1.21309\n",
            "Epoch 111/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0572 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 1.21309\n",
            "Epoch 112/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0491 - acc: 0.6004"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0567 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00112: ReduceLROnPlateau reducing learning rate to 7.719598276042205e-14.\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 1.21309\n",
            "Epoch 113/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0593 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 1.21309\n",
            "Epoch 114/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0771 - acc: 0.5804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0634 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 1.21309\n",
            "Epoch 115/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0599 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 6.947638265478867e-14.\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 1.21309\n",
            "Epoch 116/500\n",
            " 8192/57418 [===>..........................] - ETA: 11s - loss: 1.0525 - acc: 0.6082"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0594 - acc: 0.6007 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 1.21309\n",
            "Epoch 117/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0574 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 1.21309\n",
            "Epoch 118/500\n",
            "10752/57418 [====>.........................] - ETA: 10s - loss: 1.0580 - acc: 0.5985"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0620 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.252874194985491e-14.\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 1.21309\n",
            "Epoch 119/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0594 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 1.21309\n",
            "Epoch 120/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0429 - acc: 0.6116"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0626 - acc: 0.5972 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 1.21309\n",
            "Epoch 121/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0575 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00121: ReduceLROnPlateau reducing learning rate to 5.6275870194324316e-14.\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 1.21309\n",
            "Epoch 122/500\n",
            " 8128/57418 [===>..........................] - ETA: 10s - loss: 1.0740 - acc: 0.5928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0600 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 1.21309\n",
            "Epoch 123/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0605 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 1.21309\n",
            "Epoch 124/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0483 - acc: 0.6012"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0570 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00124: ReduceLROnPlateau reducing learning rate to 5.064828256502816e-14.\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 1.21309\n",
            "Epoch 125/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0598 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 1.21309\n",
            "Epoch 126/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.1078 - acc: 0.5707"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0592 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 1.21309\n",
            "Epoch 127/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0624 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 4.5583452783866037e-14.\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 1.21309\n",
            "Epoch 128/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0599 - acc: 0.5987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0608 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 1.21309\n",
            "Epoch 129/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0613 - acc: 0.5967 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 1.21309\n",
            "Epoch 130/500\n",
            "10944/57418 [====>.........................] - ETA: 10s - loss: 1.0638 - acc: 0.6012"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0590 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00130: ReduceLROnPlateau reducing learning rate to 4.102510872520688e-14.\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 1.21309\n",
            "Epoch 131/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0562 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 1.21309\n",
            "Epoch 132/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0651 - acc: 0.5974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0596 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 1.21309\n",
            "Epoch 133/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0593 - acc: 0.5993 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.692259815761805e-14.\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 1.21309\n",
            "Epoch 134/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0747 - acc: 0.5912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0620 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 1.21309\n",
            "Epoch 135/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0593 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 1.21309\n",
            "Epoch 136/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0506 - acc: 0.6022"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0594 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00136: ReduceLROnPlateau reducing learning rate to 3.3230339866515555e-14.\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 1.21309\n",
            "Epoch 137/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0583 - acc: 0.6004 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 1.21309\n",
            "Epoch 138/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0341 - acc: 0.6124"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0563 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 1.21309\n",
            "Epoch 139/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0600 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00139: ReduceLROnPlateau reducing learning rate to 2.9907305270000274e-14.\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 1.21309\n",
            "Epoch 140/500\n",
            " 8192/57418 [===>..........................] - ETA: 10s - loss: 1.0428 - acc: 0.6058"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0605 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 1.21309\n",
            "Epoch 141/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0634 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 1.21309\n",
            "Epoch 142/500\n",
            "11008/57418 [====>.........................] - ETA: 9s - loss: 1.0579 - acc: 0.5947"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0557 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00142: ReduceLROnPlateau reducing learning rate to 2.6916573218340942e-14.\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 1.21309\n",
            "Epoch 143/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0600 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 1.21309\n",
            "Epoch 144/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 0.9999 - acc: 0.6287"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0615 - acc: 0.5958 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 1.21309\n",
            "Epoch 145/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0621 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00145: ReduceLROnPlateau reducing learning rate to 2.4224915286643126e-14.\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 1.21309\n",
            "Epoch 146/500\n",
            " 8192/57418 [===>..........................] - ETA: 10s - loss: 1.0656 - acc: 0.5918"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0572 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 1.21309\n",
            "Epoch 147/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0581 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 1.21309\n",
            "Epoch 148/500\n",
            "11008/57418 [====>.........................] - ETA: 9s - loss: 1.0563 - acc: 0.5982 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0648 - acc: 0.5962 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1802423757978814e-14.\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 1.21309\n",
            "Epoch 149/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0603 - acc: 0.5961 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 1.21309\n",
            "Epoch 150/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0838 - acc: 0.5871"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0597 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 1.21309\n",
            "Epoch 151/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0597 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.962218077231721e-14.\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 1.21309\n",
            "Epoch 152/500\n",
            " 7872/57418 [===>..........................] - ETA: 10s - loss: 1.0632 - acc: 0.5913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0602 - acc: 0.5966 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 1.21309\n",
            "Epoch 153/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0620 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 1.21309\n",
            "Epoch 154/500\n",
            "10688/57418 [====>.........................] - ETA: 10s - loss: 1.0674 - acc: 0.5945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0587 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00154: ReduceLROnPlateau reducing learning rate to 1.765996254261956e-14.\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 1.21309\n",
            "Epoch 155/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0621 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 1.21309\n",
            "Epoch 156/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.1071 - acc: 0.5744"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0564 - acc: 0.5998 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 1.21309\n",
            "Epoch 157/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0589 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00157: ReduceLROnPlateau reducing learning rate to 1.5893966440823534e-14.\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 1.21309\n",
            "Epoch 158/500\n",
            " 8256/57418 [===>..........................] - ETA: 11s - loss: 1.0611 - acc: 0.5996"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0623 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 1.21309\n",
            "Epoch 159/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0618 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 1.21309\n",
            "Epoch 160/500\n",
            "10688/57418 [====>.........................] - ETA: 10s - loss: 1.0516 - acc: 0.6008"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0593 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.4304570101673042e-14.\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 1.21309\n",
            "Epoch 161/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0632 - acc: 0.5966 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 1.21309\n",
            "Epoch 162/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0563 - acc: 0.5990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0635 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 1.21309\n",
            "Epoch 163/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0582 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.2874113396437598e-14.\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 1.21309\n",
            "Epoch 164/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0596 - acc: 0.6026"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0603 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 1.21309\n",
            "Epoch 165/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0570 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 1.21309\n",
            "Epoch 166/500\n",
            "10880/57418 [====>.........................] - ETA: 10s - loss: 1.0636 - acc: 0.5912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0594 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00166: ReduceLROnPlateau reducing learning rate to 1.1586701751861977e-14.\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 1.21309\n",
            "Epoch 167/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0638 - acc: 0.5965 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 1.21309\n",
            "Epoch 168/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0547 - acc: 0.5893"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0596 - acc: 0.5970 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 1.21309\n",
            "Epoch 169/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0593 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.042803157667578e-14.\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 1.21309\n",
            "Epoch 170/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0493 - acc: 0.6045"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0605 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 1.21309\n",
            "Epoch 171/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0604 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 1.21309\n",
            "Epoch 172/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0646 - acc: 0.5987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0584 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00172: ReduceLROnPlateau reducing learning rate to 9.385228647707098e-15.\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 1.21309\n",
            "Epoch 173/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0581 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 1.21309\n",
            "Epoch 174/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0253 - acc: 0.6243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0579 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 1.21309\n",
            "Epoch 175/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0607 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00175: ReduceLROnPlateau reducing learning rate to 8.446705554237492e-15.\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 1.21309\n",
            "Epoch 176/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0535 - acc: 0.6009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0590 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 1.21309\n",
            "Epoch 177/500\n",
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0611 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 1.21309\n",
            "Epoch 178/500\n",
            "10944/57418 [====>.........................] - ETA: 10s - loss: 1.0621 - acc: 0.5962"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0588 - acc: 0.6009 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00178: ReduceLROnPlateau reducing learning rate to 7.602035151279673e-15.\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 1.21309\n",
            "Epoch 179/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0609 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 1.21309\n",
            "Epoch 180/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0676 - acc: 0.5965"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0604 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 1.21309\n",
            "Epoch 181/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0617 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00181: ReduceLROnPlateau reducing learning rate to 6.841831636151706e-15.\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 1.21309\n",
            "Epoch 182/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0571 - acc: 0.6017"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0658 - acc: 0.5970 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 1.21309\n",
            "Epoch 183/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0604 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 1.21309\n",
            "Epoch 184/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0589 - acc: 0.5993"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0607 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00184: ReduceLROnPlateau reducing learning rate to 6.15764839630357e-15.\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 1.21309\n",
            "Epoch 185/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0592 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 1.21309\n",
            "Epoch 186/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0842 - acc: 0.5871"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0603 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 1.21309\n",
            "Epoch 187/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0603 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00187: ReduceLROnPlateau reducing learning rate to 5.541883480440248e-15.\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 1.21309\n",
            "Epoch 188/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0530 - acc: 0.5960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0572 - acc: 0.5968 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 1.21309\n",
            "Epoch 189/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0558 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 1.21309\n",
            "Epoch 190/500\n",
            "10752/57418 [====>.........................] - ETA: 10s - loss: 1.0527 - acc: 0.5968"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0614 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00190: ReduceLROnPlateau reducing learning rate to 4.9876949799302926e-15.\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 1.21309\n",
            "Epoch 191/500\n",
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0569 - acc: 0.6004 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 1.21309\n",
            "Epoch 192/500\n",
            "  832/57418 [..............................] - ETA: 12s - loss: 1.0728 - acc: 0.5962"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0630 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 1.21309\n",
            "Epoch 193/500\n",
            "57418/57418 [==============================] - 14s 236us/step - loss: 1.0565 - acc: 0.6019 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00193: ReduceLROnPlateau reducing learning rate to 4.488925558170229e-15.\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 1.21309\n",
            "Epoch 194/500\n",
            " 7744/57418 [===>..........................] - ETA: 11s - loss: 1.0603 - acc: 0.5975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 14s 238us/step - loss: 1.0590 - acc: 0.6006 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 1.21309\n",
            "Epoch 195/500\n",
            "57418/57418 [==============================] - 13s 235us/step - loss: 1.0583 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 1.21309\n",
            "Epoch 196/500\n",
            "10176/57418 [====>.........................] - ETA: 10s - loss: 1.0709 - acc: 0.5962"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0613 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00196: ReduceLROnPlateau reducing learning rate to 4.040033078586171e-15.\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 1.21309\n",
            "Epoch 197/500\n",
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0587 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 1.21309\n",
            "Epoch 198/500\n",
            "  576/57418 [..............................] - ETA: 12s - loss: 0.9627 - acc: 0.6528"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 14s 236us/step - loss: 1.0569 - acc: 0.6001 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 1.21309\n",
            "Epoch 199/500\n",
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0605 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00199: ReduceLROnPlateau reducing learning rate to 3.636029618261624e-15.\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 1.21309\n",
            "Epoch 200/500\n",
            " 7680/57418 [===>..........................] - ETA: 10s - loss: 1.0785 - acc: 0.5923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0602 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 1.21309\n",
            "Epoch 201/500\n",
            "57418/57418 [==============================] - 13s 232us/step - loss: 1.0594 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 1.21309\n",
            "Epoch 202/500\n",
            "10688/57418 [====>.........................] - ETA: 10s - loss: 1.0566 - acc: 0.6070"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 235us/step - loss: 1.0583 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00202: ReduceLROnPlateau reducing learning rate to 3.2724265802024955e-15.\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 1.21309\n",
            "Epoch 203/500\n",
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0601 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 1.21309\n",
            "Epoch 204/500\n",
            "  576/57418 [..............................] - ETA: 12s - loss: 1.0737 - acc: 0.5990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 230us/step - loss: 1.0569 - acc: 0.6001 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 1.21309\n",
            "Epoch 205/500\n",
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0584 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00205: ReduceLROnPlateau reducing learning rate to 2.9451839984152115e-15.\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 1.21309\n",
            "Epoch 206/500\n",
            " 7616/57418 [==>...........................] - ETA: 11s - loss: 1.0515 - acc: 0.6082"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 231us/step - loss: 1.0592 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 1.21309\n",
            "Epoch 207/500\n",
            "57418/57418 [==============================] - 14s 235us/step - loss: 1.0639 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 1.21309\n",
            "Epoch 208/500\n",
            "10496/57418 [====>.........................] - ETA: 10s - loss: 1.0470 - acc: 0.6064"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 229us/step - loss: 1.0623 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00208: ReduceLROnPlateau reducing learning rate to 2.6506655604572078e-15.\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 1.21309\n",
            "Epoch 209/500\n",
            "57418/57418 [==============================] - 13s 232us/step - loss: 1.0581 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 1.21309\n",
            "Epoch 210/500\n",
            "  576/57418 [..............................] - ETA: 13s - loss: 1.0428 - acc: 0.5920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0599 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 1.21309\n",
            "Epoch 211/500\n",
            "57418/57418 [==============================] - 13s 230us/step - loss: 1.0576 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00211: ReduceLROnPlateau reducing learning rate to 2.385598966295004e-15.\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 1.21309\n",
            "Epoch 212/500\n",
            " 7872/57418 [===>..........................] - ETA: 11s - loss: 1.0569 - acc: 0.6007"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 228us/step - loss: 1.0598 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 1.21309\n",
            "Epoch 213/500\n",
            "57418/57418 [==============================] - 14s 237us/step - loss: 1.0592 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 1.21309\n",
            "Epoch 214/500\n",
            "10432/57418 [====>.........................] - ETA: 10s - loss: 1.0713 - acc: 0.5986"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 231us/step - loss: 1.0595 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00214: ReduceLROnPlateau reducing learning rate to 2.1470391458984692e-15.\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 1.21309\n",
            "Epoch 215/500\n",
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0606 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 1.21309\n",
            "Epoch 216/500\n",
            "  576/57418 [..............................] - ETA: 13s - loss: 0.9742 - acc: 0.6389"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 230us/step - loss: 1.0592 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 1.21309\n",
            "Epoch 217/500\n",
            "57418/57418 [==============================] - 13s 231us/step - loss: 1.0605 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.932335288483346e-15.\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 1.21309\n",
            "Epoch 218/500\n",
            " 7360/57418 [==>...........................] - ETA: 11s - loss: 1.0591 - acc: 0.6023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 230us/step - loss: 1.0596 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 1.21309\n",
            "Epoch 219/500\n",
            "57418/57418 [==============================] - 13s 232us/step - loss: 1.0592 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 1.21309\n",
            "Epoch 220/500\n",
            "10240/57418 [====>.........................] - ETA: 10s - loss: 1.0551 - acc: 0.5999"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0590 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00220: ReduceLROnPlateau reducing learning rate to 1.7391016834020462e-15.\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 1.21309\n",
            "Epoch 221/500\n",
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0568 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 1.21309\n",
            "Epoch 222/500\n",
            "  576/57418 [..............................] - ETA: 13s - loss: 1.0028 - acc: 0.6406"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 228us/step - loss: 1.0619 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 1.21309\n",
            "Epoch 223/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0603 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00223: ReduceLROnPlateau reducing learning rate to 1.5651915150618416e-15.\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 1.21309\n",
            "Epoch 224/500\n",
            " 8000/57418 [===>..........................] - ETA: 10s - loss: 1.0811 - acc: 0.5940"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0582 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 1.21309\n",
            "Epoch 225/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0563 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 1.21309\n",
            "Epoch 226/500\n",
            "10816/57418 [====>.........................] - ETA: 10s - loss: 1.0493 - acc: 0.6035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0601 - acc: 0.5999 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.408672373084778e-15.\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 1.21309\n",
            "Epoch 227/500\n",
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0597 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 1.21309\n",
            "Epoch 228/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0897 - acc: 0.5952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0581 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 1.21309\n",
            "Epoch 229/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0642 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00229: ReduceLROnPlateau reducing learning rate to 1.2678050976598176e-15.\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 1.21309\n",
            "Epoch 230/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0698 - acc: 0.6009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0567 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 1.21309\n",
            "Epoch 231/500\n",
            "57418/57418 [==============================] - 13s 218us/step - loss: 1.0588 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 1.21309\n",
            "Epoch 232/500\n",
            "11072/57418 [====>.........................] - ETA: 9s - loss: 1.0725 - acc: 0.5943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0618 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00232: ReduceLROnPlateau reducing learning rate to 1.1410246260103185e-15.\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 1.21309\n",
            "Epoch 233/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0583 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 1.21309\n",
            "Epoch 234/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.1217 - acc: 0.5796"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0616 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 1.21309\n",
            "Epoch 235/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0605 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00235: ReduceLROnPlateau reducing learning rate to 1.0269221729384074e-15.\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 1.21309\n",
            "Epoch 236/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0564 - acc: 0.6009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0628 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 1.21309\n",
            "Epoch 237/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0644 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 1.21309\n",
            "Epoch 238/500\n",
            "11072/57418 [====>.........................] - ETA: 9s - loss: 1.0613 - acc: 0.5968 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0577 - acc: 0.5998 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00238: ReduceLROnPlateau reducing learning rate to 9.242299842319286e-16.\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 1.21309\n",
            "Epoch 239/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0594 - acc: 0.5999 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 1.21309\n",
            "Epoch 240/500\n",
            " 1344/57418 [..............................] - ETA: 11s - loss: 1.0695 - acc: 0.5960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0612 - acc: 0.5988 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00240: val_loss did not improve from 1.21309\n",
            "Epoch 241/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0583 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00241: ReduceLROnPlateau reducing learning rate to 8.318069476922531e-16.\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 1.21309\n",
            "Epoch 242/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0377 - acc: 0.6074"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0576 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 1.21309\n",
            "Epoch 243/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0605 - acc: 0.5993 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 1.21309\n",
            "Epoch 244/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0401 - acc: 0.6068"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0586 - acc: 0.6017 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00244: ReduceLROnPlateau reducing learning rate to 7.486262529230277e-16.\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 1.21309\n",
            "Epoch 245/500\n",
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0618 - acc: 0.5964 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 1.21309\n",
            "Epoch 246/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0592 - acc: 0.6034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0612 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 1.21309\n",
            "Epoch 247/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0617 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00247: ReduceLROnPlateau reducing learning rate to 6.737636228661646e-16.\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 1.21309\n",
            "Epoch 248/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0731 - acc: 0.5939"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0615 - acc: 0.5965 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 1.21309\n",
            "Epoch 249/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0574 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 1.21309\n",
            "Epoch 250/500\n",
            "11072/57418 [====>.........................] - ETA: 9s - loss: 1.0670 - acc: 0.6004 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0593 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00250: ReduceLROnPlateau reducing learning rate to 6.063872605795482e-16.\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 1.21309\n",
            "Epoch 251/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0590 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 1.21309\n",
            "Epoch 252/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0739 - acc: 0.6079"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0592 - acc: 0.6014 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 1.21309\n",
            "Epoch 253/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0578 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00253: ReduceLROnPlateau reducing learning rate to 5.45748558344395e-16.\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 1.21309\n",
            "Epoch 254/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0684 - acc: 0.5943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0615 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 1.21309\n",
            "Epoch 255/500\n",
            "23296/57418 [===========>..................] - ETA: 7s - loss: 1.0686 - acc: 0.5944"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2z5Xq5RgyJgn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.save_weights(\"drive/face_expr_model2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBUGjVtXyUDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "23394b7d-473a-430c-f678-1aa83338ba7e"
      },
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test, Y_test, batch_size=batch_size)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3589/3589 [==============================] - 0s 68us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2448785724530946, 0.5402619114291471]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "RlI2rjGdI85C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model3 - My own"
      ]
    },
    {
      "metadata": {
        "id": "JQhWxjYBAiaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Model3():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
        "  model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfA9kpRUNSit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3=Model3()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R4NakEqqxw1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "gen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    validation_split=0.2, \n",
        "    horizontal_flip=True, vertical_flip=True)\n",
        "train_generator = gen.flow(X_train, Y_train, batch_size=128)\n",
        " \n",
        "model3.compile(loss='categorical_crossentropy'\n",
        ", optimizer=Adam()\n",
        ", metrics=['accuracy']\n",
        ")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d3Dfmh5nxa5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3.load_weights(\"drive/face_expr_model3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zuvOjzW8JRxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1944
        },
        "outputId": "ec890a91-892f-495a-87a5-7d8a4948a2cb"
      },
      "cell_type": "code",
      "source": [
        "model3.fit_generator(train_generator, steps_per_epoch=50, epochs=1000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 2/50 [>.............................] - ETA: 3s - loss: 1.7792 - acc: 0.2539"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:799: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:807: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 3s 66ms/step - loss: 1.6887 - acc: 0.3125\n",
            "Epoch 2/1000\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 1.6902 - acc: 0.3042\n",
            "Epoch 3/1000\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 1.6824 - acc: 0.3131\n",
            "Epoch 4/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6693 - acc: 0.3255\n",
            "Epoch 5/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6847 - acc: 0.3142\n",
            "Epoch 6/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6733 - acc: 0.3131\n",
            "Epoch 7/1000\n",
            " 5/50 [==>...........................] - ETA: 3s - loss: 1.6974 - acc: 0.3047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6842 - acc: 0.3095\n",
            "Epoch 8/1000\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 1.7034 - acc: 0.3077\n",
            "Epoch 9/1000\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 1.6871 - acc: 0.3195\n",
            "Epoch 10/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6792 - acc: 0.3174\n",
            "Epoch 11/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6856 - acc: 0.3192\n",
            "Epoch 12/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6653 - acc: 0.3284\n",
            "Epoch 13/1000\n",
            " 4/50 [=>............................] - ETA: 3s - loss: 1.6614 - acc: 0.3359"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6881 - acc: 0.3147\n",
            "Epoch 14/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6983 - acc: 0.3119\n",
            "Epoch 15/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6703 - acc: 0.3172\n",
            "Epoch 16/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6797 - acc: 0.3139\n",
            "Epoch 17/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6782 - acc: 0.3255\n",
            "Epoch 18/1000\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 1.6715 - acc: 0.3183\n",
            "Epoch 19/1000\n",
            " 4/50 [=>............................] - ETA: 3s - loss: 1.7049 - acc: 0.3340"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6841 - acc: 0.3175\n",
            "Epoch 20/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6742 - acc: 0.3175\n",
            "Epoch 21/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6614 - acc: 0.3309\n",
            "Epoch 22/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6846 - acc: 0.3133\n",
            "Epoch 23/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6700 - acc: 0.3322\n",
            "Epoch 24/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6652 - acc: 0.3205\n",
            "Epoch 25/1000\n",
            " 3/50 [>.............................] - ETA: 3s - loss: 1.6378 - acc: 0.3203"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 77ms/step - loss: 1.6738 - acc: 0.3137\n",
            "Epoch 26/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6759 - acc: 0.3147\n",
            "Epoch 27/1000\n",
            "50/50 [==============================] - 4s 81ms/step - loss: 1.6786 - acc: 0.3158\n",
            "Epoch 28/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6515 - acc: 0.3377\n",
            "Epoch 29/1000\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 1.6619 - acc: 0.3337\n",
            "Epoch 30/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6760 - acc: 0.3117\n",
            "Epoch 31/1000\n",
            " 3/50 [>.............................] - ETA: 3s - loss: 1.6445 - acc: 0.3542"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6687 - acc: 0.3142\n",
            "Epoch 32/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6723 - acc: 0.3259\n",
            "Epoch 33/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6753 - acc: 0.3194\n",
            "Epoch 34/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6607 - acc: 0.3333\n",
            "Epoch 35/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6603 - acc: 0.3194\n",
            "Epoch 36/1000\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 1.6710 - acc: 0.3183\n",
            "Epoch 37/1000\n",
            " 3/50 [>.............................] - ETA: 3s - loss: 1.6855 - acc: 0.3177"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6556 - acc: 0.3273\n",
            "Epoch 38/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6628 - acc: 0.3262\n",
            "Epoch 39/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6576 - acc: 0.3223\n",
            "Epoch 40/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6493 - acc: 0.3323\n",
            "Epoch 41/1000\n",
            "50/50 [==============================] - 4s 77ms/step - loss: 1.6732 - acc: 0.3159\n",
            "Epoch 42/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6572 - acc: 0.3284\n",
            "Epoch 43/1000\n",
            " 3/50 [>.............................] - ETA: 3s - loss: 1.6511 - acc: 0.3229"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6494 - acc: 0.3355\n",
            "Epoch 44/1000\n",
            "50/50 [==============================] - 4s 80ms/step - loss: 1.6521 - acc: 0.3331\n",
            "Epoch 45/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6631 - acc: 0.3266\n",
            "Epoch 46/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6450 - acc: 0.3325\n",
            "Epoch 47/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6596 - acc: 0.3244\n",
            "Epoch 48/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6604 - acc: 0.3302\n",
            "Epoch 49/1000\n",
            " 3/50 [>.............................] - ETA: 3s - loss: 1.6652 - acc: 0.3177"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6502 - acc: 0.3311\n",
            "Epoch 50/1000\n",
            "50/50 [==============================] - 4s 79ms/step - loss: 1.6607 - acc: 0.3362\n",
            "Epoch 51/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6538 - acc: 0.3342\n",
            "Epoch 52/1000\n",
            "50/50 [==============================] - 4s 78ms/step - loss: 1.6520 - acc: 0.3334\n",
            "Epoch 53/1000\n",
            "15/50 [========>.....................] - ETA: 2s - loss: 1.6354 - acc: 0.3370"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qSth_XTcMwv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " model3.save_weights(\"drive/face_expr_model3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQzCcQQWOBxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f2a5ab0d-0e84-43ef-a967-c1cc9df1e10e"
      },
      "cell_type": "code",
      "source": [
        "model3.evaluate(X_validation, Y_valid, batch_size=batch_size)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3589/3589 [==============================] - 0s 134us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.670193523608665, 0.31735859574232633]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "qNHEl5EC4YhG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model 4 "
      ]
    },
    {
      "metadata": {
        "id": "Lln36skXL0w9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hYkrLGOp4cxl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Model4():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(7,7), input_shape=(48,48,1)))\n",
        "  model.add(Conv2D(32, (5, 5), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVQqRsWCNjPn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model4 = Model4()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uJdqFwcB5jnG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_reducer3 = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
        "tensorboard3 = TensorBoard(log_dir='./logs')\n",
        "early_stopper3 = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
        "checkpointer3 = ModelCheckpoint(\"/drive\", monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9M2ajRN529S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model4.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x_WBAB825_z2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1833
        },
        "outputId": "061a3b50-6a08-454e-d9b4-1c9130aee95c"
      },
      "cell_type": "code",
      "source": [
        "# overfitting\n",
        "model4.fit(X_train,Y_train,\n",
        "          batch_size=128,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=(X_validation, Y_valid),\n",
        "          shuffle=True,\n",
        "          callbacks=[lr_reducer3, tensorboard3, checkpointer3])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 57418 samples, validate on 3589 samples\n",
            "Epoch 1/100\n",
            "57418/57418 [==============================] - 20s 342us/step - loss: 1.2872 - acc: 0.5114 - val_loss: 1.3423 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00001: val_loss improved from 1.34719 to 1.34231, saving model to /drive\n",
            "Epoch 2/100\n",
            "45824/57418 [======================>.......] - ETA: 3s - loss: 1.2945 - acc: 0.5080"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 19s 339us/step - loss: 1.2983 - acc: 0.5071 - val_loss: 1.3386 - val_acc: 0.4940\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.34231 to 1.33856, saving model to /drive\n",
            "Epoch 3/100\n",
            "57418/57418 [==============================] - 19s 338us/step - loss: 1.2925 - acc: 0.5093 - val_loss: 1.3334 - val_acc: 0.4829\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.33856 to 1.33339, saving model to /drive\n",
            "Epoch 4/100\n",
            "12928/57418 [=====>........................] - ETA: 14s - loss: 1.3011 - acc: 0.5021"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 20s 340us/step - loss: 1.3003 - acc: 0.5040 - val_loss: 1.3140 - val_acc: 0.4999\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.33339 to 1.31400, saving model to /drive\n",
            "Epoch 5/100\n",
            "57418/57418 [==============================] - 19s 339us/step - loss: 1.3065 - acc: 0.5017 - val_loss: 1.3283 - val_acc: 0.4929\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.31400\n",
            "Epoch 6/100\n",
            " 8064/57418 [===>..........................] - ETA: 16s - loss: 1.2906 - acc: 0.5055"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "20480/57418 [=========>....................] - ETA: 12s - loss: 1.2991 - acc: 0.5021"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-00797d6f7733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           callbacks=[lr_reducer3, tensorboard3, checkpointer3])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_6KlM2yn6J3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}