{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "56zu04MAchOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "1fcb3000-31de-4976-af70-630cd8f0d9b0"
      },
      "cell_type": "code",
      "source": [
        "# for mounting drive with google colabs\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VIcp0a35KSHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnHOW57MKWV0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_jsMmkQq0TD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5755ba53-2ebb-4a38-e154-4ead3a463951"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  drive\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AwcI6o1NkCAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import time \n",
        "import os\n",
        "import cv2\n",
        "import datetime\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ep4jky9PJHZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reading data"
      ]
    },
    {
      "metadata": {
        "id": "Qz-FqetJmBTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('drive/fer2013.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvcWR4P4VMqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ce29861-1103-41e3-c0fa-cef1f8f44a8b"
      },
      "cell_type": "code",
      "source": [
        "data['Usage'].unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Training', 'PublicTest', 'PrivateTest'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "KLS-6PRJUbNQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_train = data.loc[data['Usage']=='Training']\n",
        "public_test = data.loc[data['Usage']=='PublicTest']\n",
        "private_test = data.loc[data['Usage']=='PrivateTest']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W94GR_DZmHXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "41b712ac-2a56-4d49-8317-e666656935cc"
      },
      "cell_type": "code",
      "source": [
        "data_train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "mbUnTOc_WCyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "94f4afb5-ca3c-4947-f11c-60decaab66f1"
      },
      "cell_type": "code",
      "source": [
        "public_test.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28709</th>\n",
              "      <td>0</td>\n",
              "      <td>254 254 254 254 254 249 255 160 2 58 53 70 77 ...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28710</th>\n",
              "      <td>1</td>\n",
              "      <td>156 184 198 202 204 207 210 212 213 214 215 21...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28711</th>\n",
              "      <td>4</td>\n",
              "      <td>69 118 61 60 96 121 103 87 103 88 70 90 115 12...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28712</th>\n",
              "      <td>6</td>\n",
              "      <td>205 203 236 157 83 158 120 116 94 86 155 180 2...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28713</th>\n",
              "      <td>3</td>\n",
              "      <td>87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...</td>\n",
              "      <td>PublicTest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels       Usage\n",
              "28709        0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...  PublicTest\n",
              "28710        1  156 184 198 202 204 207 210 212 213 214 215 21...  PublicTest\n",
              "28711        4  69 118 61 60 96 121 103 87 103 88 70 90 115 12...  PublicTest\n",
              "28712        6  205 203 236 157 83 158 120 116 94 86 155 180 2...  PublicTest\n",
              "28713        3  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...  PublicTest"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "BtpLXlF4WG0I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "53e9cbfe-c9cd-4e90-a10c-7682cde9a0a0"
      },
      "cell_type": "code",
      "source": [
        "private_test.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32298</th>\n",
              "      <td>0</td>\n",
              "      <td>170 118 101 88 88 75 78 82 66 74 68 59 63 64 6...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32299</th>\n",
              "      <td>5</td>\n",
              "      <td>7 5 8 6 7 3 2 6 5 4 4 5 7 5 5 5 6 7 7 7 10 10 ...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32300</th>\n",
              "      <td>6</td>\n",
              "      <td>232 240 241 239 237 235 246 117 24 24 22 13 12...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32301</th>\n",
              "      <td>4</td>\n",
              "      <td>200 197 149 139 156 89 111 58 62 95 113 117 11...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32302</th>\n",
              "      <td>2</td>\n",
              "      <td>40 28 33 56 45 33 31 78 152 194 200 186 196 20...</td>\n",
              "      <td>PrivateTest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       emotion                                             pixels        Usage\n",
              "32298        0  170 118 101 88 88 75 78 82 66 74 68 59 63 64 6...  PrivateTest\n",
              "32299        5  7 5 8 6 7 3 2 6 5 4 4 5 7 5 5 5 6 7 7 7 10 10 ...  PrivateTest\n",
              "32300        6  232 240 241 239 237 235 246 117 24 24 22 13 12...  PrivateTest\n",
              "32301        4  200 197 149 139 156 89 111 58 62 95 113 117 11...  PrivateTest\n",
              "32302        2  40 28 33 56 45 33 31 78 152 194 200 186 196 20...  PrivateTest"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "2gyerwiGNZ8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "545128fa-aa9b-418d-a66a-673e6d69d6ee"
      },
      "cell_type": "code",
      "source": [
        "data_train.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>28709.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.317427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.876632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            emotion\n",
              "count  28709.000000\n",
              "mean       3.317427\n",
              "std        1.876632\n",
              "min        0.000000\n",
              "25%        2.000000\n",
              "50%        3.000000\n",
              "75%        5.000000\n",
              "max        6.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "dXhgd_VRK9mH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "k = data_train.iloc[1,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7musTnWRMMhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8c9670e-8818-4f4c-f738-2646dc2c2f9f"
      },
      "cell_type": "code",
      "source": [
        "len(k.split())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "gXUbIpYURgAN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "## Transforming csv to understandable image data"
      ]
    },
    {
      "metadata": {
        "id": "lhU2G8EKOeHP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "data_train = shuffle(data_train)\n",
        "public_test = shuffle(public_test)\n",
        "private_test = shuffle(private_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVU6a7pnMT1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7de782a3-71f0-4507-c0c9-9e02c70ae3dc"
      },
      "cell_type": "code",
      "source": [
        "train = np.array(data_train.iloc[:,1])\n",
        "validation = np.array(private_test.iloc[:,1])\n",
        "test = np.array(public_test.iloc[:,1])\n",
        "print(train.shape, test.shape, validation.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709,) (3589,) (3589,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-KKN2c-lPv5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = train.reshape(28709,1)\n",
        "test = test.reshape(3589,1)\n",
        "validation = validation.reshape(3589,1)\n",
        "X_train_flip = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ll4rh-3ZP3np",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ad3b29a-6119-411b-da6d-b6dd339d96eb"
      },
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28709, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "e-n86LvepCPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_augmentation(img):\n",
        "  img = cv2.flip(img.reshape(48,48), 1)\n",
        "  return np.array(img.reshape(48,48,1)).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "74JKfL9yO981",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reform_data_aug(img_str):\n",
        "  t1 = img_str[0].split()\n",
        "  t2 = np.array(t1).astype(np.float32)\n",
        "  t3 = t2.reshape(48, 48, 1)\n",
        "\n",
        "  X_train_flip.append(data_augmentation(t3))\n",
        "  return t3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PY2eyjItszJi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reform_data(img_str):\n",
        "  t1 = img_str[0].split()\n",
        "  t2 = np.array(t1).astype(np.float32)\n",
        "  t3 = t2.reshape(48, 48, 1)\n",
        "  return t3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v-SVD4HjNwN7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_1 = np.apply_along_axis(reform_data_aug, 1, train)\n",
        "X_test = np.apply_along_axis(reform_data, 1, test)\n",
        "X_validation = np.apply_along_axis(reform_data, 1, validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQod7SNzsWK7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50b40eb6-ab09-4005-8521-159b9fd14a87"
      },
      "cell_type": "code",
      "source": [
        "np.array(X_train_flip).shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28709, 48, 48, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "WZz2eBuiq1QX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72bba77d-66a7-43bd-d0f1-ce5fd55997d4"
      },
      "cell_type": "code",
      "source": [
        "X_train = np.array(list(X_train_1) + X_train_flip)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57418, 48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_ZEDOnwDNxLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88e3ed3e-c810-4c03-a854-b3bafe301b17"
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_test.shape, X_validation.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57418, 48, 48, 1) (3589, 48, 48, 1) (3589, 48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VbThqV1cRZaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "78f2d474-c133-4b7f-da8f-db1eee29e0d1"
      },
      "cell_type": "code",
      "source": [
        "# Sample image\n",
        "plt.imshow(X_train[0].reshape(48,48))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0a8f146780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD6CAYAAACI7Fo9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXuQXkWZxp/JzGQyM8kkIeR+4ZIM\nDSSIQCgJagLBEG+sZUVWay0Uw4KXKCpa5VaJtSCWu0Jls4UgSAQxsSxcylJJRbOuqIgImqCJckkb\nIJMEc5mQkMskmcnc9o+57DlPPzNfz5B882X7/f2Tr0/669OnT/ec8z7f+75d1tnZCcMw/n8zbKg7\nYBjGyccWumEkgC10w0gAW+iGkQC20A0jAWyhG0YCVAz2i865FQAuA9AJ4LPe+/UnrFeGYZxQBrXQ\nnXMLANR77+c5584D8BCAeX3V37JlS++P9TNmzMD27dtRXl6eq3Po0KHge8OHD8+VOzo6gjr8vWHD\nwpeURx55JFc+evRoUOf48eO5ck1NTe/nW2+9FV/72tfwoQ99KFenqakpaOfZZ58NjjHKd4H7XVER\n3prW1tY++9jDgQMHAACf/vSncc8998hrLSsry5X5XgBAc3NzcKytra3fdhQx7aix5mvj+6PaHjVq\nVFBn3759ufL1118f1Pn2t78dHJswYUKu/LGPfSyoU11dDQA488wz0dDQIMeR72vMmKk6Me1Mnz69\nz8YH++p+FYCfAID3/kUAY51zdTFfrKqqGuQph44pU6YMdRcGzMSJE4e6C4PiVBzrU2FOD3ahTwKw\nN1Pe233MMIwSpGwwLrDOuQcArPXe/7S7/DsAS733f1P1W1paOk+Fv3qGcYrT56v7YMW4ncg/wacA\n2NVX5e3bt/d+rq+vx5YtW04pG/1b3/oWPvWpT51SNvodd9yBr3zlK6ecjd4z1qeSje6cg/e+FGz0\nPtsc7EL/BYDbAXzbOXcxgJ3e+8ODbAuAXsR8jCcIEE5StdB27erzb1AvR44cyZXf9a535cqzZ8/G\nwYMHc8f+9Kc/Be2ohdXe3p4rq8nP16oWOt9cdbOPHTvW+7mxsTE4NxAuGjVBBzvZ+I+YulYex8OH\n81Nnz549GD16dO7YiBEjgnZef/31XJkfDD1tZXn66aeDOnPnzg2O/fjHP86Vzz333KDOwoULc2U1\nPysrK3PlmIV+MhiUje69/z2AZ51zvwdwN4BlJ7RXhmGcUAb9O7r3/l9OZEcMwzh5mGecYSTAoJ/o\nA4Htz46ODmkXMmxfKhvslVdeyZWV3cy23P79+4M6bIOxGDNhwgRs2rQpd+zvf/970I4S2mLsTRba\n1LWy/b9z586gTvZ7Bw4ckDYh28iqzz1CUxYWyFQf+Z7xdanz7d69OyizRqFEVq7z2muvBXWmTZuW\nK//qV78K6lxzzTXBsUmT8r8W/+xnPwvqnH322QC6xLiGhobecha225X2wtem7gevITUe/WFPdMNI\nAFvohpEAttANIwFsoRtGAhRFjFMogY6JERz+8Ic/5MqvvvpqUIfFuKxTSQ8zZ87MlXfs2BGUWfxS\nziCqz+ywo66VXYTZ0QIAWlpacmUldGWFxt27d0tvMW6HHVYALbTV1eXjlpSoyIKdEgP5WlnAa29v\nR2NjY7/tAuEYsdMTEN4PJQIrUfW8887LldetWxfUWbt2LQBg8eLFWLt2LZYuXRrU4TFSDkwxjlDM\nQF3X7YluGAlgC90wEsAWumEkQFFsdLYnOjs7g2PKbmUbTDlEbN68OVdmZxAgdJCZMWNGUGfs2LG5\n8tatW3Plbdu2Bba+stGVLcnnV/Yvj4ey5dQYMdnrP3jwoAyyYRtZ1VH2PxPTR+Ugwk4kPPZjx44N\n7GZ2YAFCpx51LtZjTj/99KDO3/4WRldfeeWVubJK5JENkHn66adxwQUXBHXmzcsnXlL3PsYZhu12\ns9ENwwiwhW4YCWAL3TASwBa6YSTAkDnMsJDDzhhAKLZw1g8AgWMFR0IBoXChMo2ysMbtNjY2BnWU\nYKVSHnGWk3HjxgV1WIBhpxYgFNFqa2uDOuPHj8995nMDoWilnHPUtXGflLDEx1TbDAuYNTU1gaNP\nT4qsLDw/VH8YNc9UFOC2bdty5TPOOCOos2XLlt7Phw4dkpFxzrlcWYmB3G8ltPGxgWaqsSe6YSSA\nLXTDSABb6IaRAEOWYYZtDhVswAEqq1evDuqwLa2cJti2VXYSO9qwrX38+PGodMfKvmKnDeWgwv1W\n48HXoRwrTjvttNxnlZmUtQZ2WAG04xGPSYz9rcajUKBHWVlZkOFHBazwvFJ7B6iAGWby5MnBMe99\nrnzhhRcGdbL2fl1dHf7yl78EdTZu3JgrX3311UEdvkexWXkHgj3RDSMBbKEbRgLYQjeMBLCFbhgJ\nMGTRazGpnB9//PFcWWUCiUmTPHXq1Fw5K1j1sHfv3lxZCYgsmqgMK0rsYccO5VTDzijKGYYFGSU8\nZvtdUVEho77YiUZF3I0cOTI4xtGDyqmGHV0GKyKxIKUy5bzRFMg9qOvn+aAiJ7NRkDNmzMDvfve7\noA6nH58/f35Qh+dHjMPMQLEnumEkgC10w0gAW+iGkQBDZqOzDaYcIp5//vlcOWYL4DFjxgR16uvr\nC7bDTizsfFFVVRWlBygHFQ5iUVlXGWVv8pgpx4qs3T58+HBZh7OlKAceFfzBtizbsUDYb+XEUmib\nooqKiig9ImYro5itv1Qf+Z6xYxaQ1w1qa2tlH9lhhrcQA4Dzzz8/V1a6hm3JZBhGQWyhG0YC2EI3\njASwhW4YCTBkGWZYJFGZUNT2SoXaUWl5OTpLCX8MR2ZVVlYGDjJKjFMiCTufKIGIBUKVYYYdK5So\nmBWE2trapEDF16b2QlfwPu9KfOJ+qz5yn2Ii99R18PeUAw/Xib1n7KCjnJyYWbNmBcc4lTRHxQEI\n9lVXzlJvFHuiG0YC2EI3jASIenV3zs0B8FMAK7z39zjnpgNYDaAcwC4A13nvw3dNwzBKgoIL3TlX\nC+CbALIRJl8FcK/3/lHn3NcBLAVw30BOzE4TKnsr29LKdmMnDs66CYT2lrJ/ldNGFmXHqv6orCts\nX6pgGLYvlY7AmVALZdM5evSo7A/3W9mthZxxAJ3N9tChQ7lyjN3M41FTUxP0WzmRsHOUGg9uRznH\n7Nu3LzjGsD7BVFRUYNq0acFx3n77ueeeC+osWLAgVx4qG70FwLsBZHPiXgHgse7PawC848R2yzCM\nE0nBJ7r3vg1AGz0pazOv6o0AwqRbhmGUDGWxca7OudsAvNZtozd67yd0H58FYJX3/vK+vtvc3Nyp\nXlcNwzih9Bn8P9jf0Zucc9Xe+2MApiL/Wh/w0ksv9X6eM2eOtFNUBs0777yzz3Z6YJtr4cKFQR3e\nJlnZ6P39TvrAAw/gpptuCrK5KjtW/SbLQSPK3oyx0Qv9/gz833j86Ec/wpIlS6JsdHUd6ljMNsUx\nNjqPUfYhsHLlStx4441DbqPzPWtqagrq9PDQQw9h6dKlcl5lt1YGwm2UAWDZsmW5cna3nb5Q82zm\nzJl91h/sQv8lgCUAvt/977qBNsBinIr64omlJi1vlaNS9/KgqH3G2amGnVymT58epEnmzDWAzl7D\nf6BUJBRHtKmFxvusqz9O2WOHDx+WQhtPdvW2FbOvuZpsLCSpyc9je8455+TKF110UZSAyn9UVIpq\njsJT23GdeeaZwbEXXnghV1ZzJjtGdXV10qmHxeGYPyqFHKEGQ4zqfgmA5QDOBNDqnPsAgA8DeNg5\n93EA2wB87w31wjCMk0qMGPcsulR2ZtEJ741hGCcF84wzjAQoSlBLzLY4SrRhW4636QFCASJmuyWV\n9ZOzfLAYNm7cuCATqMqwojLc8DY8yk575plncuWYbZvU+bN2dFtbmxT1WNhSGV+V0wbb8kpXYbtd\ntc2BR3wPZ86cGegzTz31VNBOdttiQNvRW7duzZWV45Oy0Vn7UVpHVpytq6uTbfO8ZgcaIMxurBxv\nLMOMYRgFsYVuGAlgC90wEsAWumEkwJCle2ZhiZ1RgFA047TNQOggo9IUs2OFcpp4+eWXc2XOeLNp\n06bgO0pAbGhoCI5x2upLLrkkqMNCo/LgYqHxr3/9a1AnK+x0dnZKRxMWdlQdlZKax1Y52rBopZyK\nWLBkr7OmpqZAnFTelOxUpEReFq3UtSqvTBZeWZwD8mJkZWUlzjrrrKAOz2uei0DonHPppZcGdQa7\n3VTv99/Qtw3DOCWwhW4YCWAL3TASwBa6YSTAkKV7ZpRIwhFMyjuJBSoV4cZhf0pEe/HFF3NlFow6\nOjoCjzLliaWObd++PVdWQhenZeJoOiAUn5TwmI2Mq6yslFFPHPWmoq5UZBz3OyYFs/KeY0/FbArk\nJUuW4Mknnwy8B2P2uYtJ5azCXZXQxRGGhVJJdXZ2Ss/N119/PVfmdGCqjhqzNxq9Zk90w0gAW+iG\nkQC20A0jAYpio7NdVFZWFrUFEdugKuqM6ygbjCOolFMLRx7xd0aOHBnYyMrWVrYt27Lqe5ymStly\n7KCi7LasLTl69GipR3Af1ZjF7Cuuvsd9YvsTCJ1ReC40NTUF90OllmYdRUUuxvRHbf3F90hFAWad\nmvra/oqdvNR9ZYcqngtAOB9jcz32YE90w0gAW+iGkQC20A0jAWyhG0YCDJkYx44lSjRiAUY5w7BT\njRJNWHxSTi0cZcVpm6dMmYJJkyb12y6gr4P7xGmbgdBBQ+URj0knlBXsRowYISPMuG3VZwULZEoc\nZdFI9ZHHTQmfb3nLW3LHVPQY3zOVxovn3s6d4RYEas9yjlZUqb2ygmV5ebmce7yngBIMeYyUYMdz\nL/ae9Z5jQLUNwzglsYVuGAlgC90wEqAoNrra64vtNOXIz4Edyi7hQAJO76u+p+xWdmx485vfnCsv\nWrQosNtj0vsCoU2s9oJnm1Blj+G2VUrmrGYxatQoaetz8MdAnS96UE4sPEYqtTWfn7ctcs5F2dac\nGUYF+fB2TyoLjAog4sAbte8fp9ZWjjdsW7OmBHRt95VFaUhvFHuiG0YC2EI3jASwhW4YCWAL3TAS\nYMjSPXO0WowzjBLsOMpIOTawsMPiDwC86U1vypXPPvvsoMwi2hNPPBG0o9JCs2ilnCa43yziAGGU\nlYpeYzFORcqpPdsYlTqZHVtUH/l8KsKNRTNOgXzo0KHAaeQHP/hB0A47zChHE75nN9xwQ1Dn+uuv\nD47xfnBKDMwKjc3NzXJftTlz5uTKSkBlATPGGUaNa3/YE90wEsAWumEkgC10w0iAIcsCy/alyrLJ\nji0qiILtImV/slON2g+bj23cuLH38/z587Fx40bcdddduTq8bRAAXHDBBcEx3v9aOWjMnTs3V1b2\nNx9TNmlMZhbO8KK0D3WM21J95MAO1Q5nUGGbtLGxEatWrcod++QnPxm085nPfCZXVttYLV++PFf+\n7ne/G9SZNWtWcIwdbdT8zG7b1dbWJuce33vVDs9rFRzzRrEnumEkgC10w0gAW+iGkQBRNrpz7k4A\nb++u/28A1gNYDaAcwC4A13nvwzSuhmGUBAUXunPuSgBzvPfznHPjAPwZwOMA7vXeP+qc+zqApQDu\n66sNlWGGhRMltPEx3loJCFPlKkGEM4+oOq+88kquvHLlyt7P8+fPx8qVK4OIskceeSRoZ968ecEx\njuC66aabgjq//vWvc+VFixYFdXivbeUclM1es3///sAZAwhFNZXaWR1jRxeVopuz5yjHDr6vGzZs\nyJWfeeaZQFS85ZZbgnY4M8x5550X1Ln55ptz5bVr1wZ11N7rLBAq4TPrVNTe3h6InEA419Q8Z4FO\nRRwONsKwh5hX998CuLb78wEAtQCuAPBY97E1AN7xhnphGMZJpWwgfymcczeh6xV+sfd+QvexmQBW\ne+8v7+t7zc3NnSoG3DCME0qffrHRv6M7594H4AYAVwPYEtN4Dy+//HLv59mzZ+P5558PXo349Q0I\nf29Wr+6/+c1vcmWVIICTSpx//vlBHU5IsGLFit7Pq1evxnXXXYcnn3wyV+fBBx8M2hnsqzvvuKpe\n3fm1WL2694zZypUrceONN8pXd/5tV72Wqld3TtCokijw67R6dZ84cWKu/Oc//7n381NPPYW3vvWt\ngX8EJ5lQ51Kv7jzPFi9eHNRRxzgegscMAHbt2gUAuPvuu3HzzTcH5h8AXH311bmySnLJv5ur39F5\nPqhYBPbPzxIrxi0G8GUA7/TeH3TONTnnqr33xwBMBRB6/GdQQS0xTvkxtkvWaQEIs6kC4cTi7wDh\nouE6e/bswdve9rbcsauuuipoZ/PmzcExtm1vv/32oM5ll12WKysnDratVfaWrG3b3NwsnVq4P2rS\nqDcwXvzqD42y2xkeW/5jpP44KeckHiPOCgMA69evz5V5nAH9Bytmq+vsfGxqapLjyMEw7IgDhE5F\nKgMR11HZdfujYG3n3GgAdwF4r/e+55HySwBLuj8vAbBuQGc1DKOoxDzRPwjgdAD/lXmd+SiA7zjn\nPg5gG4DvnZzuGYZxIii40L33DwB4QPxXaEQahlGSmGecYSTAkEWvMSqrBgsOHIUGhIKQEoN4T2yV\nFpiFrYsuuigoszq9ZcsWMCoyjTOoqMw0LOwpx4oelbcHJZhlxbjq6mop2nC6ZdWOyvjD9dSWVJw9\nh68dCIUlFhnHjRsXCKgPP/xw0A6jfing/qjoMfWrAzsnFdrq6/jx4/L8fP3qvnLbKt0zj5mK1OsP\ne6IbRgLYQjeMBLCFbhgJMGQ2OjvRKAcatp2mTJkS1GEbXdk33I6qwxlO+Vxjx44N7KL7778/aEc5\n9bAjh7pW3pZHOWiwba20Bs4Cq2x05cDEqDFiu13Z8dxvZZPyPePxOXjwYHA/1LXyOCobOcbWjsmw\no+4Zb8mk7Ga+VrXVFusR3GfVjtoOrD/siW4YCWAL3TASwBa6YSSALXTDSICiiHEs7HR0dARRVSry\nJ2ZfcRZXVDss9ijnHBZfuJ0dO3ZEiT8Kjo6KcepRggyfTzm6ZI+NGDFCCk18LuX4oq6NRbvJkycH\ndfjalNDH957TP1dVVQV9VCInowREvo/qumKcilQUIGeYUXW4T2prJ47CU/eDRU61rVd/2BPdMBLA\nFrphJIAtdMNIAFvohpEARRHjWAApLy8PhC0lkLGIpsQ49s5S4k+MkMOwiHPgwIGoPitBiIU1FdEV\nk4KJxS/ldcbRayq1NQuYLDwBcaJVzHUoUZG/xyJWa2tr4Bmn0kQxSgzje6aEt5i0TEogy8612CSr\nKm0VR9QpLzwex4Gmf7YnumEkgC10w0gAW+iGkQBFsdHVlkxsYyhHFxXBxbCdGpOdQ9lbDNttR48e\nlY4/jLK1OfJI2a3cR7ZR1TFly2U1i8rKyiAXPBDa6MpGjYnEUk4brCMohx22/1V/WFeJycyi+sxj\nFDM/1DE1Rnwd6n5wnyZNmhTU4bmv7G+z0Q3DKIgtdMNIAFvohpEAttANIwGKIsbFpC5SYgtH+ijx\nZ9q0abnytm3bgjocHaX2seZU0ix+NDc3S8eSGPh6lSDEkWgqMoyFHTWOnIJYOcywY4nqj0q5VFtb\nmysrhyF2YFIiFju/8LgOGzYsSojldvg+A2HKpZg9/1SflDNO9p5VV1dHiXFqDqlxZGIchvrDnuiG\nkQC20A0jAWyhG0YCDFm6Z7Z5lH3DwQ+qDm8Q/8ILLwR12JZVDjNsS7ETQ3t7e/C9GEcLQNvAjAp2\nKNS2shuztvWRI0eiUlurLYnU1kWsI+zYsSOow1pHjN2qsvuwM4oaV9YRVPAS6wpqzNQ2Wnz9yhkn\na2/X1dVJzYQ1C86cA4TjqvqodKWBYE90w0gAW+iGkQC20A0jAWyhG0YClEyGGQU7rShhiYUU3scK\nCIUUdW4WQFjYqaqqCiLTlLASkylGZW9hsUkJSyz2qEiorJPRzp07o/qjxEkVTch9VE4cLPSpdpTQ\nyWU+pu4Z14lx/FEioxLaxowZkyurvc6yc2bMmDFRUZHKEUhFdzJ8HSoCsj/siW4YCWAL3TASoOCr\nu3OuBsDDACYCGAHgDgCbAKwGUA5gF4DrvPeF3xENwxgSYmz0awBs8N7f6Zw7A8D/AHgKwL3e+0ed\nc18HsBTAfQM5cUxGVYYznAChrTJu3LigDttuyrGB7T12YhgxYkRgJyn7Vzl2cGCHstG5j6odHiNV\n58UXX8x9Vs4gA81O0gPrGCoQifukbFu2ifketrW1Bd9TY8bHVAANO6yoPisbnY+xzc7nq6uri8oc\npOaMCjxiuO2BZjYuuNC99z/MFKcDeBXAFQA+0X1sDYAvYoAL3TCM4hGtujvnfg9gGoD3Avhl5lW9\nEUAYU2kYRslQNpDXOOfcmwGsAjDZez+++9gsAKu895f39b2WlpZO9XpkGMYJpc/frGPEuEsANHrv\nd3jvNzrnKgAcds5Ve++PAZgKINwLNsPWrVt7P5977rnYvHlzYF+tW7cu+N4f//jHXPnCCy8M6syb\nNy9Xfuyxx4I6bAPF2OjZJAaPPvoorr32Wuzbt6/fdoE4G53tRiD8fVclKGD7sr6+PqjzxBNPAADW\nr1+PSy+9VNrofExdx2mnnRYcO+OMM3JlleiBr0ONx65du3Ll7O/xa9aswTXXXBPoESrQY/v27bly\nTFCJSl4yfvz44NiUKVNyZTUePff1S1/6Er7xjW9E2ejqOmLgtpcsWRLUmTt3bp/fjznrfABnAPic\nc24igJEA1gFYAuD73f+Gq7QALD4p5wu+cWpi8QBwtJKqo24It82Lc9iwYVF7bcekN1b7mse0o/5A\nMLNnz859VplilKMPo8Qe7pNy2FFpqhn+g8nfUW00NDQEx/iPoXKY4ahA9WapBMMYsm319cYa49jC\n90PNYf7D19jYGNPFXmIW+v0AHnTOPQmgGsAyABsArHLOfRzANgDfG9BZDcMoKjGq+zEA/yT+a5E4\nZhhGCWKecYaRACWzJZNy9mc7WTnVsA2qHCI4U42ydQttEVVRURHYciqIQbXNtmRMQI9qh+1AZRde\nfPHFuc+cSRcAtmzZUrA/6hjrGErYYtTWyixIKQ2FNRsltMUEK3EdZf+qceQ+qvvB21/FBPCoPrIj\nmBLsWB9hQbMQ9kQ3jASwhW4YCWAL3TASwBa6YSTAkKV7ZucG5QzDIokS41jIUB5lLIAohxVum4W2\nysrKoD/KsSMmy4gSbbjtqVOnBnVYkFIOO9nvTZ06FQsWLAjqsBeicqpRYz1r1qxceeHChUGdn//8\n57myitYq5Ah17NixYIyUYMbXr0QsFt/UvY/xQozZjks57MQ4WfH8VMI0i4ExEW9Z7IluGAlgC90w\nEsAWumEkQFFsdOXowYENyi5hBxVlA8VkpmGbUNlyfC524qiqqgrsu5itlgBt7zMcHaWy6cTYexs2\nbADQFd20YcMGmRllxowZubLakkmdn6OjlDMMR5QpBxUO4lDzIyYrEF9/THZfZesrJ6uYrZxitsPm\ne6/OxcdU0BGfP2Zb6Sz2RDeMBLCFbhgJYAvdMBLAFrphJMCQbcmkUvwyHL0W45Cg2uE6Ki1wIWeY\nkSNHRjnDKHGQz1dXVxfU4X7HpEVSTkbZdlpbW7FmzZqgDqfEVoKdGmtO7cWCKhCKWEqwK7SVUkdH\nRzBnYpyMYkRWlU0mJiW1Evqy91UJowp1XzkLjhrXwabo7sGe6IaRALbQDSMBbKEbRgIMmY3OGUSU\nTci2rbJT2CaOcTRR9lahrXtqamqCAA2lByh7d//+/f2eCwivQzlWsG5QKGCkra1N9vHVV1/NldWY\nqUCXbNruvvrIY6tsdP6eyrDC/VY2cEwWGHZyinWYidnKOHv+ioqKKOctpTWwRqACb1jTUu30hz3R\nDSMBbKEbRgLYQjeMBLCFbhgJUBQxTm1vxFvKKDGOxSYltrBoo0SkmP2vWGxh4W/48OGBSKLEMAWL\nLUpU5D4pQYaFpEIpkKuqqqL2FVfZSpQzDl9HjCCk+sjZWlQ2mZi94PmeKccXHkeVKUY5UPExNWdY\njFNzWAnRDH9PXQdHqykBtT/siW4YCWAL3TASwBa6YSSALXTDSICiiHEqOmnPnj25Y0qkYCFHeSex\nIKZEJCYm5S6LNsOHDw/EMCWaKNGIBSElpLBHnWp77NixubK61ux1lJWVSW8t3vtc1VHCUsxe9Oy9\nF+MtxlRXVwf3VQl/LJApoY0FXCWqKTGu0Lm4T+3t7fJa+fxq7vG1KdE5JpKzP+yJbhgJYAvdMBLA\nFrphJEBRbHS2Qdrb2wPHFmWTst2s7KQYxwq23ZR9UyijSEVFRZTDTMzWPaqPfP2jR48O6rBtrSLl\nsnXa29tlKme2E9W51P7bMVtb8T2KiQxjKisrZdsMj3WMbRtjjyvU97Jzr6OjQ9ro3EcVPceRnGqe\nxzje9Ic90Q0jAWyhG0YCRL26O+eqATwH4A4AjwNYDaAcwC4A13nv45y+DcMYEmKf6LcC6EmT8lUA\n93rv3w7gJQBLT0bHDMM4cRR8ojvnzgVwPoC13YeuAPCJ7s9rAHwRwH39tcGiVUtLSyDGKRGLRasY\nhxkltLFIo+rw+QfreKMEIXWMYecg3osNCMeDRRwgnyp43759UX1Ue33FpLtSYiSnxFaiGl8bC4a1\ntbVR6a9Z2FLXyudX1xXjfKIEsmxE2fHjx6XIyn2MicBU5+LvDTT9c8wTfTmAWzLl2syreiOAyQM6\no2EYRaesv78MzrmPAJjhvf+ac+42AA0A7vTeT+j+/1kAVnnvL+/vJC0tLZ3qZwXDME4off5uWejV\n/T0AznbOvRfANAAtAJqcc9Xe+2MApgLYWejsO3bs6P08a9YsvPTSS7jvvvzbPvtRA+ErjXqdZX/r\nnTvD7nAd1Q7/lpx9df/CF76A5cuXBz7q/Ls2oBNfxNTh17VzzjknqBPz6t6T0OOhhx7C0qVLo3Z8\nUf1RvuUxmWpPP/30XFntSsO/SWdf3VesWIHPf/7zwbWp+ADe4UT1h8+v/POVecHH1HX0mDzLli3D\nvffeG2TJVedT7ezevTtXLmQmAPp3/bvvvjs41ttmn/8DwHv/wZ7PmSf65QCWAPh+97/r+msDCCfS\nkSNHgkkTs/90jN2oYPtbba08BojSAAAGm0lEQVTEi0gFtbDdHuPYAISLRjmosP6gNAKe7GqP7JgU\nxNy2mjQxgT+FHF8AvUD5+nny19XVRW2jFZMmme9RrKNJTL3s+B8+fLjgtk1A4a2dAG1/87XGbA+W\nO8eAanfxrwA+6px7EsBpAL43iDYMwygi0S6w3vvbMsVFJ74rhmGcLMwzzjASwBa6YSRAUaLXWEFV\nanGhDB591WGnDSV2xKRJZtGII8MqKysDMTAmo4iqF5NuWgltLGqywg3klej6+vpAmVbnj9kfTaEc\nTVjoU/e6kNA2bNiwYBxVpF7M3msxolqMk5O619m511fqbx4jJSrGZCBiAVNFJfaHPdENIwFsoRtG\nAthCN4wEKIqNzhlf9+zZM+D9p/uCbSDVTozDTEyQANt7yt6KsffUufiY8hQ866yzcuU5c+YEderr\n63s/v//978e4ceOCOuzRp4Ix1LXFZCtl7zDeix3IB94AwGuvvZYrd3R0RGV4ZR1jsJmEY46pOZM9\nX3l5+aCz1/A4qnPFeOr1hz3RDSMBbKEbRgLYQjeMBLCFbhgJUBQxjsWXffv2BeKKEoRYpFChkzH7\nWMeIcTF7fceIgzF7nytHE74O5bAyffr0XHn8+PFBnUmTJuU+x2wRperECHRK/GLBULXDoZvs/FFR\nURGIYcqJZKBZVoC4iDvVtsqncKLEOL4fqh12llKOUP1hT3TDSABb6IaRALbQDSMBimKjs4NGU1NT\nlI0eY7twOyq4gO0rVYeDFjijR3V1dWDbxzpfsP2vrpXteBXEwXa7cprI2padnZ0yTRQ7mqjAE3Ud\n3G91PzhNV8zWUnxdNTU1QZ/UPWMNJ8ZGVk4+ytaPSVPV0NDQ+7m1tTXq/ErX4GMqUw5rFCodWn/Y\nE90wEsAWumEkgC10w0gAW+iGkQBFEeNY6GptbY3a7znGQSWmnZh9tAulQB42bFjQzmAj7pRow040\nKqPJ/v37c2V1/qyINGrUKBkFx6hc56ptFvGU4w8LSep+PPfcc7mymh8x6Yz5fsQ4S6nrUmPNzkk8\n9kAofMZsf6Xq8HxQIis7FSkHov6wJ7phJIAtdMNIAFvohpEARbHRlb3LTiQx2Tpj7HiViYRt0Jgt\nkRXsxKK2G1bOMDHZdHiMVB/37t1bsE6P3VhWVobOzk7pWDFy5MhcWdnDykFlwoQJubK6H9w27ysG\nANu3b8+V2d48ePBgVPZUNa8Y7mPM9stAOGe2bdsW1Mn2saOjIzpghuE5rPrD81pl7u0Pe6IbRgLY\nQjeMBLCFbhgJYAvdMBKgbDBZOgzDOLWwJ7phJIAtdMNIAFvohpEAttANIwFsoRtGAthCN4wEKIqv\nOwA451YAuAxAJ4DPeu/XF+vcA8U5NwfATwGs8N7f45ybDmA1gHIAuwBc570PncGHEOfcnQDejq57\n+m8A1qOE++ycqwHwMICJAEYAuAPAJpRwn7M456oBPIeufj+OEu93UZ7ozrkFAOq99/MA3ADg7mKc\ndzA452oBfBNdN6+HrwK413v/dgAvAVg6FH3rC+fclQDmdI/vOwH8J0q8zwCuAbDBe78AwD8C+A+U\nfp+z3AqgJxtFyfe7WK/uVwH4CQB4718EMNY5N7ANnotHC4B3A9iZOXYFgMe6P68B8I4i96kQvwVw\nbffnAwBqUeJ99t7/0Ht/Z3dxOoBXUeJ97sE5dy6A8wGs7T50BUq838Va6JMAZGMs93YfKzm8923e\ne47/rM28ijUCmFzkbvWL977de9+TwP0GAD9Dife5B+fc7wH8AMDncIr0GcByALdkyiXf76ES4wYX\nuFsalGzfnXPvQ9dC/zT9V8n22Xt/OYB/APB95PtZkn12zn0EwNPe+619VCnJfhdroe9E/gk+BV2i\nxalCU7f4AgBTkX+tLwmcc4sBfBnAu7z3B1HifXbOXdItcsJ7vxFdIuLhUu5zN+8B8D7n3DMA/hnA\nV1DiYw0Ub6H/AsAHAMA5dzGAnd77w/1/paT4JYAl3Z+XAFg3hH0JcM6NBnAXgPd673sEopLuM4D5\nAL4AAM65iQBGovT7DO/9B733l3rvLwPwHXSp7iXf76JFrznn/h1dN7cDwDLv/aainHiAOOcuQZcN\ndiaAVgB/B/BhdP0UNALANgAf896HOYKHCOfcTQBuA/C3zOGPomsilmqfqwE8iC4hrhrA7QA2AFiF\nEu0z45y7DUADgP9GiffbwlQNIwHMM84wEsAWumEkgC10w0gAW+iGkQC20A0jAWyhG0YC2EI3jASw\nhW4YCfC/ivVHkJChXssAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0a8f4364a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WYB7ls1PTmSe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalization "
      ]
    },
    {
      "metadata": {
        "id": "SlrUS2YXSi3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "X_validation = X_validation/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwsAGZnLT6LD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One Hot Encoding"
      ]
    },
    {
      "metadata": {
        "id": "DddjY8kpTpRH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_train = data_train['emotion']\n",
        "Y_test = public_test['emotion']\n",
        "Y_validation = private_test['emotion']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pqH6KdN9ZmaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b34220b4-379d-47d2-c868-fd744246611e"
      },
      "cell_type": "code",
      "source": [
        "print(Y_train.shape, Y_test.shape, Y_validation.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28709,) (3589,) (3589,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zvweNZgLZo4R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def onehot(Y, C):\n",
        "  Y = np.eye(C)[Y].T\n",
        "  return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VsNoXc5HbDHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92c7c650-bb20-4f08-b576-a3e12170b6cf"
      },
      "cell_type": "code",
      "source": [
        "data['emotion'].unique()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 4, 6, 3, 5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "yNWyfJYNbMFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_test = onehot(Y_test, 7).T\n",
        "Y_train = onehot(Y_train, 7).T\n",
        "Y_valid = onehot(Y_validation, 7).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HLB4j6WbcWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "337ac7b2-0b96-44c1-d613-ba8daf19e31f"
      },
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28709, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "0iMkGB1wtYNj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_train = np.array(list(Y_train) + list(Y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pw_OvfvF4rBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "630aca8f-b3c9-47d3-9010-7a058464d422"
      },
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57418, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "h_86wLen4vJR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train = shuffle(X_train, Y_train, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJ2_D-9K69nZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76c72aad-5682-49db-f03d-9b74b7766867"
      },
      "cell_type": "code",
      "source": [
        "print(X_validation.shape, Y_valid.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3589, 48, 48, 1) (3589, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GpkHLbumbdvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clear memory\n",
        "del data\n",
        "del data_train\n",
        "del public_test\n",
        "del private_test\n",
        "del Y_validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "00cI1F-aSFhF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Models\n",
        "Taking 3 - 4 models for ensemble voting"
      ]
    },
    {
      "metadata": {
        "id": "3o79vhYEYKiI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b447ced0-7a35-44da-a8b7-db3e836e6b85"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_M_Ig2oSLY1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1-Basic 5 layer model"
      ]
    },
    {
      "metadata": {
        "id": "eKGfnDEiSNlh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 100\n",
        "input_shape = (48, 48, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_aM9YHvESPbQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Model1(input_shape=(48,48,1)):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=input_shape, data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
        "  model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(2*2*2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(2*2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(2*num_features, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(num_labels, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zI99IQASU6t-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1213
        },
        "outputId": "cee7f128-e3bd-47ab-b91b-ceec85455f4f"
      },
      "cell_type": "code",
      "source": [
        "model1 = Model1()\n",
        "model1.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 23, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 5,905,863\n",
            "Trainable params: 5,902,151\n",
            "Non-trainable params: 3,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8piOth2iZGjD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8U4Oe6R5d95Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir='./logs')\n",
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(\"/drive\", monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QjWde_EayatC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.load_weights(\"drive/face_expr_model1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C3ganIoqepJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "a6cce23b-a54d-483a-9ba1-85a650ff6e31"
      },
      "cell_type": "code",
      "source": [
        "model1.fit(X_train,Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=300,\n",
        "          verbose=1,\n",
        "          validation_data=(X_validation, Y_valid),\n",
        "          shuffle=True,\n",
        "          callbacks=[lr_reducer, early_stopper, tensorboard, checkpointer])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 57418 samples, validate on 3589 samples\n",
            "Epoch 1/300\n",
            "43840/57418 [=====================>........] - ETA: 27s - loss: 0.3085 - acc: 0.8987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 120s 2ms/step - loss: 0.3182 - acc: 0.8963 - val_loss: 1.2731 - val_acc: 0.6709\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.27313, saving model to /drive\n",
            "Epoch 2/300\n",
            "17408/57418 [========>.....................] - ETA: 1:19 - loss: 0.3355 - acc: 0.8915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3466 - acc: 0.8868 - val_loss: 1.2974 - val_acc: 0.6489\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.27313\n",
            "Epoch 3/300\n",
            "10944/57418 [====>.........................] - ETA: 1:32 - loss: 0.3368 - acc: 0.8865"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3456 - acc: 0.8844 - val_loss: 1.3302 - val_acc: 0.6559\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.27313\n",
            "Epoch 4/300\n",
            " 8896/57418 [===>..........................] - ETA: 1:36 - loss: 0.3441 - acc: 0.8853"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3552 - acc: 0.8833 - val_loss: 1.2190 - val_acc: 0.6620\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.27313 to 1.21900, saving model to /drive\n",
            "Epoch 5/300\n",
            " 7488/57418 [==>...........................] - ETA: 1:40 - loss: 0.3480 - acc: 0.8868"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3649 - acc: 0.8793 - val_loss: 1.3062 - val_acc: 0.6601\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.21900\n",
            "Epoch 6/300\n",
            " 7872/57418 [===>..........................] - ETA: 1:39 - loss: 0.4933 - acc: 0.8368"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3878 - acc: 0.8713 - val_loss: 1.2542 - val_acc: 0.6704\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.21900\n",
            "Epoch 7/300\n",
            " 8000/57418 [===>..........................] - ETA: 1:38 - loss: 0.3756 - acc: 0.8776"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3630 - acc: 0.8800 - val_loss: 1.3386 - val_acc: 0.6592\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.21900\n",
            "Epoch 8/300\n",
            " 6144/57418 [==>...........................] - ETA: 1:42 - loss: 0.4050 - acc: 0.8674"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3581 - acc: 0.8812 - val_loss: 1.2405 - val_acc: 0.6634\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.21900\n",
            "Epoch 9/300\n",
            " 7424/57418 [==>...........................] - ETA: 1:40 - loss: 0.3625 - acc: 0.8836"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3454 - acc: 0.8872 - val_loss: 1.2977 - val_acc: 0.6565\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.21900\n",
            "Epoch 10/300\n",
            " 7808/57418 [===>..........................] - ETA: 1:39 - loss: 0.3410 - acc: 0.8922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3412 - acc: 0.8890 - val_loss: 1.3018 - val_acc: 0.6581\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.21900\n",
            "Epoch 11/300\n",
            " 6144/57418 [==>...........................] - ETA: 1:42 - loss: 0.3206 - acc: 0.8910"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3303 - acc: 0.8903 - val_loss: 1.2574 - val_acc: 0.6665\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.21900\n",
            "Epoch 12/300\n",
            " 7424/57418 [==>...........................] - ETA: 1:40 - loss: 0.3074 - acc: 0.8994"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 117s 2ms/step - loss: 0.3177 - acc: 0.8942 - val_loss: 1.3263 - val_acc: 0.6701\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.21900\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a489375f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "rXNlohhle1zS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.save_weights(\"drive/face_expr_model1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLtAOTy6wMeA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c19c29da-5ef9-4ac6-8fa6-f4c7554fd675"
      },
      "cell_type": "code",
      "source": [
        "model1.evaluate(X_test, Y_test, batch_size=batch_size)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3589/3589 [==============================] - 2s 695us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3717110243372415, 0.670660351076874]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "mmSMPa3hfV9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYA-f0zNlcsn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2- Model2 - https://arxiv.org/pdf/1706.01509"
      ]
    },
    {
      "metadata": {
        "id": "cWN5Pq1-lgi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Model2(input_shape=(48,48,1)):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(10, (5,5), activation='relu', kernel_regularizer=l2(0.01), input_shape=input_shape))\n",
        "  model.add(MaxPooling2D())\n",
        "#   model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(10, (5,5), activation='relu'))\n",
        "  model.add(MaxPooling2D())\n",
        "#   model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(10, (3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D()) \n",
        "#   model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_labels, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "39oaxtDKxcCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "ab3c3917-df62-4f6f-abbc-dc8dbdc83094"
      },
      "cell_type": "code",
      "source": [
        "model2 = Model2()\n",
        "model2.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 44, 44, 10)        260       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 22, 22, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 18, 18, 10)        2510      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 9, 9, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 7, 7, 10)          910       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 90)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               23296     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 60,775\n",
            "Trainable params: 60,775\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zpHBq76n6hJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr_reducer2 = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=3, verbose=1)\n",
        "tensorboard2 = TensorBoard(log_dir='./logs')\n",
        "early_stopper2 = EarlyStopping(monitor='val_loss', min_delta=0, patience=8, verbose=1, mode='auto')\n",
        "checkpointer2 = ModelCheckpoint(\"/drive\", monitor='val_loss', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MRGCpXAsxfv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bRbbgsPExK8F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.load_weights(\"drive/face_expr_model2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gh4JqzcLxnLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20612
        },
        "outputId": "447bb2b8-0f2c-4328-8538-b2367dd9f169"
      },
      "cell_type": "code",
      "source": [
        "model2.fit(X_train,Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=500,\n",
        "          verbose=1,\n",
        "          validation_data=(X_validation, Y_valid),\n",
        "          shuffle=True,\n",
        "          callbacks=[lr_reducer2, tensorboard2, checkpointer2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 57418 samples, validate on 3589 samples\n",
            "Epoch 1/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0620 - acc: 0.5969 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 1.21309\n",
            "Epoch 2/500\n",
            "50816/57418 [=========================>....] - ETA: 1s - loss: 1.0611 - acc: 0.5987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0620 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.21309\n",
            "Epoch 3/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0606 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.21309\n",
            "Epoch 4/500\n",
            "18880/57418 [========>.....................] - ETA: 8s - loss: 1.0741 - acc: 0.5960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0644 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.426607435297324e-12.\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.21309\n",
            "Epoch 5/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0598 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.21309\n",
            "Epoch 6/500\n",
            " 2880/57418 [>.............................] - ETA: 12s - loss: 1.0792 - acc: 0.5938"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0603 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.21309\n",
            "Epoch 7/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0614 - acc: 0.5968 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.0839467698301484e-12.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.21309\n",
            "Epoch 8/500\n",
            " 9024/57418 [===>..........................] - ETA: 10s - loss: 1.0601 - acc: 0.5961"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0617 - acc: 0.5988 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.21309\n",
            "Epoch 9/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0618 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.21309\n",
            "Epoch 10/500\n",
            "11520/57418 [=====>........................] - ETA: 9s - loss: 1.0641 - acc: 0.5943 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0589 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.775552053815855e-12.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.21309\n",
            "Epoch 11/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0617 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.21309\n",
            "Epoch 12/500\n",
            " 1600/57418 [..............................] - ETA: 12s - loss: 1.0690 - acc: 0.5875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0611 - acc: 0.5998 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.21309\n",
            "Epoch 13/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0619 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.497996926496826e-12.\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.21309\n",
            "Epoch 14/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0569 - acc: 0.6001"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0583 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.21309\n",
            "Epoch 15/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0562 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.21309\n",
            "Epoch 16/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0755 - acc: 0.5975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0635 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.248197331425339e-12.\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.21309\n",
            "Epoch 17/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0603 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.21309\n",
            "Epoch 18/500\n",
            " 1600/57418 [..............................] - ETA: 12s - loss: 1.0526 - acc: 0.6038"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0603 - acc: 0.6001 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.21309\n",
            "Epoch 19/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0589 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.023377559251527e-12.\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.21309\n",
            "Epoch 20/500\n",
            " 8192/57418 [===>..........................] - ETA: 10s - loss: 1.0488 - acc: 0.6052"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0579 - acc: 0.6012 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.21309\n",
            "Epoch 21/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0628 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.21309\n",
            "Epoch 22/500\n",
            "10944/57418 [====>.........................] - ETA: 10s - loss: 1.0598 - acc: 0.5960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0595 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.8210398033263743e-12.\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.21309\n",
            "Epoch 23/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0606 - acc: 0.5970 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.21309\n",
            "Epoch 24/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0411 - acc: 0.6064"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0586 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.21309\n",
            "Epoch 25/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0609 - acc: 0.5956 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.638935862025015e-12.\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.21309\n",
            "Epoch 26/500\n",
            " 8384/57418 [===>..........................] - ETA: 10s - loss: 1.0623 - acc: 0.5980"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0549 - acc: 0.5993 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.21309\n",
            "Epoch 27/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0571 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.21309\n",
            "Epoch 28/500\n",
            "11264/57418 [====>.........................] - ETA: 10s - loss: 1.0624 - acc: 0.6025"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0596 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.4750422563068744e-12.\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.21309\n",
            "Epoch 29/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0590 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.21309\n",
            "Epoch 30/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0670 - acc: 0.6034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0610 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.21309\n",
            "Epoch 31/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0624 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.3275380794652846e-12.\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.21309\n",
            "Epoch 32/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0440 - acc: 0.6077"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0570 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.21309\n",
            "Epoch 33/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0583 - acc: 0.6009 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.21309\n",
            "Epoch 34/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0417 - acc: 0.6051"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0596 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.1947843105500345e-12.\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.21309\n",
            "Epoch 35/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0629 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.21309\n",
            "Epoch 36/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0427 - acc: 0.5893"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0611 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.21309\n",
            "Epoch 37/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0628 - acc: 0.5965 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.0753058599793919e-12.\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.21309\n",
            "Epoch 38/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0696 - acc: 0.5921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0600 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.21309\n",
            "Epoch 39/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0613 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.21309\n",
            "Epoch 40/500\n",
            "11200/57418 [====>.........................] - ETA: 9s - loss: 1.0476 - acc: 0.6029 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0577 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.677752739814527e-13.\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.21309\n",
            "Epoch 41/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0596 - acc: 0.5972 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.21309\n",
            "Epoch 42/500\n",
            " 1600/57418 [..............................] - ETA: 12s - loss: 1.0802 - acc: 0.5988"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0598 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.21309\n",
            "Epoch 43/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0604 - acc: 0.5970 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 8.709977075520293e-13.\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.21309\n",
            "Epoch 44/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0722 - acc: 0.5962"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0629 - acc: 0.5972 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 1.21309\n",
            "Epoch 45/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0573 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.21309\n",
            "Epoch 46/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0446 - acc: 0.6083"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0620 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 7.838979465546459e-13.\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 1.21309\n",
            "Epoch 47/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0580 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 1.21309\n",
            "Epoch 48/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0603 - acc: 0.5908"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0615 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.21309\n",
            "Epoch 49/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0610 - acc: 0.5988 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 7.055081616570008e-13.\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 1.21309\n",
            "Epoch 50/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0677 - acc: 0.6035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0592 - acc: 0.6015 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 1.21309\n",
            "Epoch 51/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0586 - acc: 0.6004 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 1.21309\n",
            "Epoch 52/500\n",
            "11328/57418 [====>.........................] - ETA: 10s - loss: 1.0598 - acc: 0.5988"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0618 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 6.349573210967519e-13.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 1.21309\n",
            "Epoch 53/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0613 - acc: 0.5967 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 1.21309\n",
            "Epoch 54/500\n",
            " 1600/57418 [..............................] - ETA: 12s - loss: 1.0627 - acc: 0.5944"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0594 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 1.21309\n",
            "Epoch 55/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0597 - acc: 0.5965 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 5.714615792292571e-13.\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 1.21309\n",
            "Epoch 56/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0587 - acc: 0.6004"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0590 - acc: 0.5971 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 1.21309\n",
            "Epoch 57/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0598 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 1.21309\n",
            "Epoch 58/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0501 - acc: 0.6007"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0591 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 5.143154457008803e-13.\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 1.21309\n",
            "Epoch 59/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0619 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 1.21309\n",
            "Epoch 60/500\n",
            " 1344/57418 [..............................] - ETA: 11s - loss: 1.0469 - acc: 0.5885"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0585 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 1.21309\n",
            "Epoch 61/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0641 - acc: 0.5962 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 4.628838816151531e-13.\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 1.21309\n",
            "Epoch 62/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0435 - acc: 0.6070"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0609 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 1.21309\n",
            "Epoch 63/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0628 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 1.21309\n",
            "Epoch 64/500\n",
            "11264/57418 [====>.........................] - ETA: 10s - loss: 1.0670 - acc: 0.5945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0623 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 4.1659546905908895e-13.\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 1.21309\n",
            "Epoch 65/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0616 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 1.21309\n",
            "Epoch 66/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0881 - acc: 0.6039"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0613 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 1.21309\n",
            "Epoch 67/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0589 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 3.7493592215318006e-13.\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 1.21309\n",
            "Epoch 68/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0479 - acc: 0.6045"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0598 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 1.21309\n",
            "Epoch 69/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0613 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 1.21309\n",
            "Epoch 70/500\n",
            "11200/57418 [====>.........................] - ETA: 10s - loss: 1.0638 - acc: 0.5946"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0607 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 3.3744232993786204e-13.\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 1.21309\n",
            "Epoch 71/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0619 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 1.21309\n",
            "Epoch 72/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0578 - acc: 0.6124"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0627 - acc: 0.5968 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 1.21309\n",
            "Epoch 73/500\n",
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0589 - acc: 0.6006 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 3.036981067018954e-13.\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 1.21309\n",
            "Epoch 74/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0618 - acc: 0.5928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0586 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 1.21309\n",
            "Epoch 75/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0610 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 1.21309\n",
            "Epoch 76/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0621 - acc: 0.5913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0613 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 2.7332828383443144e-13.\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 1.21309\n",
            "Epoch 77/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0592 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 1.21309\n",
            "Epoch 78/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0542 - acc: 0.6029"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0575 - acc: 0.6003 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 1.21309\n",
            "Epoch 79/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0614 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00079: ReduceLROnPlateau reducing learning rate to 2.4599546032989804e-13.\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 1.21309\n",
            "Epoch 80/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0771 - acc: 0.5921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0597 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 1.21309\n",
            "Epoch 81/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0601 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 1.21309\n",
            "Epoch 82/500\n",
            "11328/57418 [====>.........................] - ETA: 9s - loss: 1.0405 - acc: 0.6054 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0569 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 2.213959240547278e-13.\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 1.21309\n",
            "Epoch 83/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0579 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 1.21309\n",
            "Epoch 84/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0850 - acc: 0.5975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0612 - acc: 0.6011 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 1.21309\n",
            "Epoch 85/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0598 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.9925633408870991e-13.\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 1.21309\n",
            "Epoch 86/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0593 - acc: 0.6007"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0588 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 1.21309\n",
            "Epoch 87/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0597 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 1.21309\n",
            "Epoch 88/500\n",
            "11328/57418 [====>.........................] - ETA: 10s - loss: 1.0434 - acc: 0.6047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0574 - acc: 0.6004 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.7933069580092915e-13.\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 1.21309\n",
            "Epoch 89/500\n",
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0583 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 1.21309\n",
            "Epoch 90/500\n",
            " 1344/57418 [..............................] - ETA: 11s - loss: 1.0532 - acc: 0.5997"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0575 - acc: 0.5966 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 1.21309\n",
            "Epoch 91/500\n",
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0589 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.6139762866029111e-13.\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 1.21309\n",
            "Epoch 92/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0633 - acc: 0.5949"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0640 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 1.21309\n",
            "Epoch 93/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0590 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 1.21309\n",
            "Epoch 94/500\n",
            "11136/57418 [====>.........................] - ETA: 10s - loss: 1.0591 - acc: 0.5989"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0604 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.4525786579426202e-13.\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 1.21309\n",
            "Epoch 95/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0578 - acc: 0.6012 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 1.21309\n",
            "Epoch 96/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0573 - acc: 0.5967"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0592 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 1.21309\n",
            "Epoch 97/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0609 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.3073208287401813e-13.\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 1.21309\n",
            "Epoch 98/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0476 - acc: 0.5963"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0605 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 1.21309\n",
            "Epoch 99/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0617 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 1.21309\n",
            "Epoch 100/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0552 - acc: 0.6028"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0576 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.1765887336688888e-13.\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 1.21309\n",
            "Epoch 101/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0585 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 1.21309\n",
            "Epoch 102/500\n",
            "  832/57418 [..............................] - ETA: 12s - loss: 1.0933 - acc: 0.5853"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0560 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 1.21309\n",
            "Epoch 103/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0627 - acc: 0.5967 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0589297993156277e-13.\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 1.21309\n",
            "Epoch 104/500\n",
            " 7872/57418 [===>..........................] - ETA: 10s - loss: 1.0590 - acc: 0.5922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0632 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 1.21309\n",
            "Epoch 105/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0608 - acc: 0.5999 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 1.21309\n",
            "Epoch 106/500\n",
            "10752/57418 [====>.........................] - ETA: 10s - loss: 1.0554 - acc: 0.6084"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0627 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00106: ReduceLROnPlateau reducing learning rate to 9.530368437786138e-14.\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 1.21309\n",
            "Epoch 107/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0605 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 1.21309\n",
            "Epoch 108/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0519 - acc: 0.6002"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0619 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 1.21309\n",
            "Epoch 109/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0610 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 8.577331350062036e-14.\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 1.21309\n",
            "Epoch 110/500\n",
            " 8192/57418 [===>..........................] - ETA: 10s - loss: 1.0623 - acc: 0.6002"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0610 - acc: 0.6010 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 1.21309\n",
            "Epoch 111/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0572 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 1.21309\n",
            "Epoch 112/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0491 - acc: 0.6004"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0567 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00112: ReduceLROnPlateau reducing learning rate to 7.719598276042205e-14.\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 1.21309\n",
            "Epoch 113/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0593 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 1.21309\n",
            "Epoch 114/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0771 - acc: 0.5804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0634 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 1.21309\n",
            "Epoch 115/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0599 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 6.947638265478867e-14.\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 1.21309\n",
            "Epoch 116/500\n",
            " 8192/57418 [===>..........................] - ETA: 11s - loss: 1.0525 - acc: 0.6082"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0594 - acc: 0.6007 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 1.21309\n",
            "Epoch 117/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0574 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 1.21309\n",
            "Epoch 118/500\n",
            "10752/57418 [====>.........................] - ETA: 10s - loss: 1.0580 - acc: 0.5985"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0620 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.252874194985491e-14.\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 1.21309\n",
            "Epoch 119/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0594 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 1.21309\n",
            "Epoch 120/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0429 - acc: 0.6116"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0626 - acc: 0.5972 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 1.21309\n",
            "Epoch 121/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0575 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00121: ReduceLROnPlateau reducing learning rate to 5.6275870194324316e-14.\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 1.21309\n",
            "Epoch 122/500\n",
            " 8128/57418 [===>..........................] - ETA: 10s - loss: 1.0740 - acc: 0.5928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0600 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 1.21309\n",
            "Epoch 123/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0605 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 1.21309\n",
            "Epoch 124/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0483 - acc: 0.6012"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0570 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00124: ReduceLROnPlateau reducing learning rate to 5.064828256502816e-14.\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 1.21309\n",
            "Epoch 125/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0598 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 1.21309\n",
            "Epoch 126/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.1078 - acc: 0.5707"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0592 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 1.21309\n",
            "Epoch 127/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0624 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 4.5583452783866037e-14.\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 1.21309\n",
            "Epoch 128/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0599 - acc: 0.5987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0608 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 1.21309\n",
            "Epoch 129/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0613 - acc: 0.5967 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 1.21309\n",
            "Epoch 130/500\n",
            "10944/57418 [====>.........................] - ETA: 10s - loss: 1.0638 - acc: 0.6012"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0590 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00130: ReduceLROnPlateau reducing learning rate to 4.102510872520688e-14.\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 1.21309\n",
            "Epoch 131/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0562 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 1.21309\n",
            "Epoch 132/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0651 - acc: 0.5974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0596 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 1.21309\n",
            "Epoch 133/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0593 - acc: 0.5993 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.692259815761805e-14.\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 1.21309\n",
            "Epoch 134/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0747 - acc: 0.5912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0620 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 1.21309\n",
            "Epoch 135/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0593 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 1.21309\n",
            "Epoch 136/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0506 - acc: 0.6022"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0594 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00136: ReduceLROnPlateau reducing learning rate to 3.3230339866515555e-14.\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 1.21309\n",
            "Epoch 137/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0583 - acc: 0.6004 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 1.21309\n",
            "Epoch 138/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0341 - acc: 0.6124"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0563 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 1.21309\n",
            "Epoch 139/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0600 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00139: ReduceLROnPlateau reducing learning rate to 2.9907305270000274e-14.\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 1.21309\n",
            "Epoch 140/500\n",
            " 8192/57418 [===>..........................] - ETA: 10s - loss: 1.0428 - acc: 0.6058"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0605 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 1.21309\n",
            "Epoch 141/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0634 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 1.21309\n",
            "Epoch 142/500\n",
            "11008/57418 [====>.........................] - ETA: 9s - loss: 1.0579 - acc: 0.5947"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0557 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00142: ReduceLROnPlateau reducing learning rate to 2.6916573218340942e-14.\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 1.21309\n",
            "Epoch 143/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0600 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 1.21309\n",
            "Epoch 144/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 0.9999 - acc: 0.6287"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0615 - acc: 0.5958 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 1.21309\n",
            "Epoch 145/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0621 - acc: 0.5994 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00145: ReduceLROnPlateau reducing learning rate to 2.4224915286643126e-14.\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 1.21309\n",
            "Epoch 146/500\n",
            " 8192/57418 [===>..........................] - ETA: 10s - loss: 1.0656 - acc: 0.5918"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0572 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 1.21309\n",
            "Epoch 147/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0581 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 1.21309\n",
            "Epoch 148/500\n",
            "11008/57418 [====>.........................] - ETA: 9s - loss: 1.0563 - acc: 0.5982 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0648 - acc: 0.5962 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1802423757978814e-14.\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 1.21309\n",
            "Epoch 149/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0603 - acc: 0.5961 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 1.21309\n",
            "Epoch 150/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0838 - acc: 0.5871"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0597 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 1.21309\n",
            "Epoch 151/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0597 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.962218077231721e-14.\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 1.21309\n",
            "Epoch 152/500\n",
            " 7872/57418 [===>..........................] - ETA: 10s - loss: 1.0632 - acc: 0.5913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0602 - acc: 0.5966 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 1.21309\n",
            "Epoch 153/500\n",
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0620 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 1.21309\n",
            "Epoch 154/500\n",
            "10688/57418 [====>.........................] - ETA: 10s - loss: 1.0674 - acc: 0.5945"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0587 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00154: ReduceLROnPlateau reducing learning rate to 1.765996254261956e-14.\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 1.21309\n",
            "Epoch 155/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0621 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 1.21309\n",
            "Epoch 156/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.1071 - acc: 0.5744"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0564 - acc: 0.5998 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 1.21309\n",
            "Epoch 157/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0589 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00157: ReduceLROnPlateau reducing learning rate to 1.5893966440823534e-14.\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 1.21309\n",
            "Epoch 158/500\n",
            " 8256/57418 [===>..........................] - ETA: 11s - loss: 1.0611 - acc: 0.5996"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0623 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 1.21309\n",
            "Epoch 159/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0618 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 1.21309\n",
            "Epoch 160/500\n",
            "10688/57418 [====>.........................] - ETA: 10s - loss: 1.0516 - acc: 0.6008"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0593 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.4304570101673042e-14.\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 1.21309\n",
            "Epoch 161/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0632 - acc: 0.5966 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 1.21309\n",
            "Epoch 162/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0563 - acc: 0.5990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0635 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 1.21309\n",
            "Epoch 163/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0582 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.2874113396437598e-14.\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 1.21309\n",
            "Epoch 164/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0596 - acc: 0.6026"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0603 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 1.21309\n",
            "Epoch 165/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0570 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 1.21309\n",
            "Epoch 166/500\n",
            "10880/57418 [====>.........................] - ETA: 10s - loss: 1.0636 - acc: 0.5912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0594 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00166: ReduceLROnPlateau reducing learning rate to 1.1586701751861977e-14.\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 1.21309\n",
            "Epoch 167/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0638 - acc: 0.5965 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 1.21309\n",
            "Epoch 168/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0547 - acc: 0.5893"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0596 - acc: 0.5970 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 1.21309\n",
            "Epoch 169/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0593 - acc: 0.6005 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.042803157667578e-14.\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 1.21309\n",
            "Epoch 170/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0493 - acc: 0.6045"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0605 - acc: 0.5973 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 1.21309\n",
            "Epoch 171/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0604 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 1.21309\n",
            "Epoch 172/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0646 - acc: 0.5987"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0584 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00172: ReduceLROnPlateau reducing learning rate to 9.385228647707098e-15.\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 1.21309\n",
            "Epoch 173/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0581 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 1.21309\n",
            "Epoch 174/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0253 - acc: 0.6243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0579 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 1.21309\n",
            "Epoch 175/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0607 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00175: ReduceLROnPlateau reducing learning rate to 8.446705554237492e-15.\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 1.21309\n",
            "Epoch 176/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0535 - acc: 0.6009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0590 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 1.21309\n",
            "Epoch 177/500\n",
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0611 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 1.21309\n",
            "Epoch 178/500\n",
            "10944/57418 [====>.........................] - ETA: 10s - loss: 1.0621 - acc: 0.5962"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0588 - acc: 0.6009 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00178: ReduceLROnPlateau reducing learning rate to 7.602035151279673e-15.\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 1.21309\n",
            "Epoch 179/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0609 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 1.21309\n",
            "Epoch 180/500\n",
            " 1088/57418 [..............................] - ETA: 12s - loss: 1.0676 - acc: 0.5965"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0604 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 1.21309\n",
            "Epoch 181/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0617 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00181: ReduceLROnPlateau reducing learning rate to 6.841831636151706e-15.\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 1.21309\n",
            "Epoch 182/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0571 - acc: 0.6017"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0658 - acc: 0.5970 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 1.21309\n",
            "Epoch 183/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0604 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 1.21309\n",
            "Epoch 184/500\n",
            "11072/57418 [====>.........................] - ETA: 10s - loss: 1.0589 - acc: 0.5993"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0607 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00184: ReduceLROnPlateau reducing learning rate to 6.15764839630357e-15.\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 1.21309\n",
            "Epoch 185/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0592 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 1.21309\n",
            "Epoch 186/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0842 - acc: 0.5871"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0603 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 1.21309\n",
            "Epoch 187/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0603 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00187: ReduceLROnPlateau reducing learning rate to 5.541883480440248e-15.\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 1.21309\n",
            "Epoch 188/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0530 - acc: 0.5960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0572 - acc: 0.5968 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 1.21309\n",
            "Epoch 189/500\n",
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0558 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 1.21309\n",
            "Epoch 190/500\n",
            "10752/57418 [====>.........................] - ETA: 10s - loss: 1.0527 - acc: 0.5968"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 226us/step - loss: 1.0614 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00190: ReduceLROnPlateau reducing learning rate to 4.9876949799302926e-15.\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 1.21309\n",
            "Epoch 191/500\n",
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0569 - acc: 0.6004 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 1.21309\n",
            "Epoch 192/500\n",
            "  832/57418 [..............................] - ETA: 12s - loss: 1.0728 - acc: 0.5962"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0630 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 1.21309\n",
            "Epoch 193/500\n",
            "57418/57418 [==============================] - 14s 236us/step - loss: 1.0565 - acc: 0.6019 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00193: ReduceLROnPlateau reducing learning rate to 4.488925558170229e-15.\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 1.21309\n",
            "Epoch 194/500\n",
            " 7744/57418 [===>..........................] - ETA: 11s - loss: 1.0603 - acc: 0.5975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 14s 238us/step - loss: 1.0590 - acc: 0.6006 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 1.21309\n",
            "Epoch 195/500\n",
            "57418/57418 [==============================] - 13s 235us/step - loss: 1.0583 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 1.21309\n",
            "Epoch 196/500\n",
            "10176/57418 [====>.........................] - ETA: 10s - loss: 1.0709 - acc: 0.5962"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0613 - acc: 0.5974 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00196: ReduceLROnPlateau reducing learning rate to 4.040033078586171e-15.\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 1.21309\n",
            "Epoch 197/500\n",
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0587 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 1.21309\n",
            "Epoch 198/500\n",
            "  576/57418 [..............................] - ETA: 12s - loss: 0.9627 - acc: 0.6528"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 14s 236us/step - loss: 1.0569 - acc: 0.6001 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 1.21309\n",
            "Epoch 199/500\n",
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0605 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00199: ReduceLROnPlateau reducing learning rate to 3.636029618261624e-15.\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 1.21309\n",
            "Epoch 200/500\n",
            " 7680/57418 [===>..........................] - ETA: 10s - loss: 1.0785 - acc: 0.5923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0602 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 1.21309\n",
            "Epoch 201/500\n",
            "57418/57418 [==============================] - 13s 232us/step - loss: 1.0594 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00201: val_loss did not improve from 1.21309\n",
            "Epoch 202/500\n",
            "10688/57418 [====>.........................] - ETA: 10s - loss: 1.0566 - acc: 0.6070"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 235us/step - loss: 1.0583 - acc: 0.6002 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00202: ReduceLROnPlateau reducing learning rate to 3.2724265802024955e-15.\n",
            "\n",
            "Epoch 00202: val_loss did not improve from 1.21309\n",
            "Epoch 203/500\n",
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0601 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00203: val_loss did not improve from 1.21309\n",
            "Epoch 204/500\n",
            "  576/57418 [..............................] - ETA: 12s - loss: 1.0737 - acc: 0.5990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 230us/step - loss: 1.0569 - acc: 0.6001 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00204: val_loss did not improve from 1.21309\n",
            "Epoch 205/500\n",
            "57418/57418 [==============================] - 13s 234us/step - loss: 1.0584 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00205: ReduceLROnPlateau reducing learning rate to 2.9451839984152115e-15.\n",
            "\n",
            "Epoch 00205: val_loss did not improve from 1.21309\n",
            "Epoch 206/500\n",
            " 7616/57418 [==>...........................] - ETA: 11s - loss: 1.0515 - acc: 0.6082"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 231us/step - loss: 1.0592 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00206: val_loss did not improve from 1.21309\n",
            "Epoch 207/500\n",
            "57418/57418 [==============================] - 14s 235us/step - loss: 1.0639 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00207: val_loss did not improve from 1.21309\n",
            "Epoch 208/500\n",
            "10496/57418 [====>.........................] - ETA: 10s - loss: 1.0470 - acc: 0.6064"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 229us/step - loss: 1.0623 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00208: ReduceLROnPlateau reducing learning rate to 2.6506655604572078e-15.\n",
            "\n",
            "Epoch 00208: val_loss did not improve from 1.21309\n",
            "Epoch 209/500\n",
            "57418/57418 [==============================] - 13s 232us/step - loss: 1.0581 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00209: val_loss did not improve from 1.21309\n",
            "Epoch 210/500\n",
            "  576/57418 [..............................] - ETA: 13s - loss: 1.0428 - acc: 0.5920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 227us/step - loss: 1.0599 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00210: val_loss did not improve from 1.21309\n",
            "Epoch 211/500\n",
            "57418/57418 [==============================] - 13s 230us/step - loss: 1.0576 - acc: 0.5978 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00211: ReduceLROnPlateau reducing learning rate to 2.385598966295004e-15.\n",
            "\n",
            "Epoch 00211: val_loss did not improve from 1.21309\n",
            "Epoch 212/500\n",
            " 7872/57418 [===>..........................] - ETA: 11s - loss: 1.0569 - acc: 0.6007"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 228us/step - loss: 1.0598 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00212: val_loss did not improve from 1.21309\n",
            "Epoch 213/500\n",
            "57418/57418 [==============================] - 14s 237us/step - loss: 1.0592 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00213: val_loss did not improve from 1.21309\n",
            "Epoch 214/500\n",
            "10432/57418 [====>.........................] - ETA: 10s - loss: 1.0713 - acc: 0.5986"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 231us/step - loss: 1.0595 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00214: ReduceLROnPlateau reducing learning rate to 2.1470391458984692e-15.\n",
            "\n",
            "Epoch 00214: val_loss did not improve from 1.21309\n",
            "Epoch 215/500\n",
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0606 - acc: 0.5976 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00215: val_loss did not improve from 1.21309\n",
            "Epoch 216/500\n",
            "  576/57418 [..............................] - ETA: 13s - loss: 0.9742 - acc: 0.6389"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 230us/step - loss: 1.0592 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00216: val_loss did not improve from 1.21309\n",
            "Epoch 217/500\n",
            "57418/57418 [==============================] - 13s 231us/step - loss: 1.0605 - acc: 0.5991 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.932335288483346e-15.\n",
            "\n",
            "Epoch 00217: val_loss did not improve from 1.21309\n",
            "Epoch 218/500\n",
            " 7360/57418 [==>...........................] - ETA: 11s - loss: 1.0591 - acc: 0.6023"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 230us/step - loss: 1.0596 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00218: val_loss did not improve from 1.21309\n",
            "Epoch 219/500\n",
            "57418/57418 [==============================] - 13s 232us/step - loss: 1.0592 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00219: val_loss did not improve from 1.21309\n",
            "Epoch 220/500\n",
            "10240/57418 [====>.........................] - ETA: 10s - loss: 1.0551 - acc: 0.5999"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0590 - acc: 0.5980 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00220: ReduceLROnPlateau reducing learning rate to 1.7391016834020462e-15.\n",
            "\n",
            "Epoch 00220: val_loss did not improve from 1.21309\n",
            "Epoch 221/500\n",
            "57418/57418 [==============================] - 13s 233us/step - loss: 1.0568 - acc: 0.5977 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00221: val_loss did not improve from 1.21309\n",
            "Epoch 222/500\n",
            "  576/57418 [..............................] - ETA: 13s - loss: 1.0028 - acc: 0.6406"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 228us/step - loss: 1.0619 - acc: 0.5992 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00222: val_loss did not improve from 1.21309\n",
            "Epoch 223/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0603 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00223: ReduceLROnPlateau reducing learning rate to 1.5651915150618416e-15.\n",
            "\n",
            "Epoch 00223: val_loss did not improve from 1.21309\n",
            "Epoch 224/500\n",
            " 8000/57418 [===>..........................] - ETA: 10s - loss: 1.0811 - acc: 0.5940"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0582 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00224: val_loss did not improve from 1.21309\n",
            "Epoch 225/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0563 - acc: 0.6000 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00225: val_loss did not improve from 1.21309\n",
            "Epoch 226/500\n",
            "10816/57418 [====>.........................] - ETA: 10s - loss: 1.0493 - acc: 0.6035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0601 - acc: 0.5999 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00226: ReduceLROnPlateau reducing learning rate to 1.408672373084778e-15.\n",
            "\n",
            "Epoch 00226: val_loss did not improve from 1.21309\n",
            "Epoch 227/500\n",
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0597 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00227: val_loss did not improve from 1.21309\n",
            "Epoch 228/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0897 - acc: 0.5952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0581 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00228: val_loss did not improve from 1.21309\n",
            "Epoch 229/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0642 - acc: 0.5975 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00229: ReduceLROnPlateau reducing learning rate to 1.2678050976598176e-15.\n",
            "\n",
            "Epoch 00229: val_loss did not improve from 1.21309\n",
            "Epoch 230/500\n",
            " 8448/57418 [===>..........................] - ETA: 10s - loss: 1.0698 - acc: 0.6009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0567 - acc: 0.5990 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00230: val_loss did not improve from 1.21309\n",
            "Epoch 231/500\n",
            "57418/57418 [==============================] - 13s 218us/step - loss: 1.0588 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00231: val_loss did not improve from 1.21309\n",
            "Epoch 232/500\n",
            "11072/57418 [====>.........................] - ETA: 9s - loss: 1.0725 - acc: 0.5943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0618 - acc: 0.5989 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00232: ReduceLROnPlateau reducing learning rate to 1.1410246260103185e-15.\n",
            "\n",
            "Epoch 00232: val_loss did not improve from 1.21309\n",
            "Epoch 233/500\n",
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0583 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00233: val_loss did not improve from 1.21309\n",
            "Epoch 234/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.1217 - acc: 0.5796"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0616 - acc: 0.5981 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00234: val_loss did not improve from 1.21309\n",
            "Epoch 235/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0605 - acc: 0.5979 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00235: ReduceLROnPlateau reducing learning rate to 1.0269221729384074e-15.\n",
            "\n",
            "Epoch 00235: val_loss did not improve from 1.21309\n",
            "Epoch 236/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0564 - acc: 0.6009"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 225us/step - loss: 1.0628 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00236: val_loss did not improve from 1.21309\n",
            "Epoch 237/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0644 - acc: 0.5987 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00237: val_loss did not improve from 1.21309\n",
            "Epoch 238/500\n",
            "11072/57418 [====>.........................] - ETA: 9s - loss: 1.0613 - acc: 0.5968 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0577 - acc: 0.5998 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00238: ReduceLROnPlateau reducing learning rate to 9.242299842319286e-16.\n",
            "\n",
            "Epoch 00238: val_loss did not improve from 1.21309\n",
            "Epoch 239/500\n",
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0594 - acc: 0.5999 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00239: val_loss did not improve from 1.21309\n",
            "Epoch 240/500\n",
            " 1344/57418 [..............................] - ETA: 11s - loss: 1.0695 - acc: 0.5960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0612 - acc: 0.5988 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00240: val_loss did not improve from 1.21309\n",
            "Epoch 241/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0583 - acc: 0.5986 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00241: ReduceLROnPlateau reducing learning rate to 8.318069476922531e-16.\n",
            "\n",
            "Epoch 00241: val_loss did not improve from 1.21309\n",
            "Epoch 242/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0377 - acc: 0.6074"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0576 - acc: 0.5985 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00242: val_loss did not improve from 1.21309\n",
            "Epoch 243/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0605 - acc: 0.5993 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00243: val_loss did not improve from 1.21309\n",
            "Epoch 244/500\n",
            "11008/57418 [====>.........................] - ETA: 10s - loss: 1.0401 - acc: 0.6068"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0586 - acc: 0.6017 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00244: ReduceLROnPlateau reducing learning rate to 7.486262529230277e-16.\n",
            "\n",
            "Epoch 00244: val_loss did not improve from 1.21309\n",
            "Epoch 245/500\n",
            "57418/57418 [==============================] - 13s 219us/step - loss: 1.0618 - acc: 0.5964 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00245: val_loss did not improve from 1.21309\n",
            "Epoch 246/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0592 - acc: 0.6034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0612 - acc: 0.5997 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00246: val_loss did not improve from 1.21309\n",
            "Epoch 247/500\n",
            "57418/57418 [==============================] - 13s 222us/step - loss: 1.0617 - acc: 0.5983 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00247: ReduceLROnPlateau reducing learning rate to 6.737636228661646e-16.\n",
            "\n",
            "Epoch 00247: val_loss did not improve from 1.21309\n",
            "Epoch 248/500\n",
            " 8256/57418 [===>..........................] - ETA: 10s - loss: 1.0731 - acc: 0.5939"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 224us/step - loss: 1.0615 - acc: 0.5965 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00248: val_loss did not improve from 1.21309\n",
            "Epoch 249/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0574 - acc: 0.5995 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00249: val_loss did not improve from 1.21309\n",
            "Epoch 250/500\n",
            "11072/57418 [====>.........................] - ETA: 9s - loss: 1.0670 - acc: 0.6004 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0593 - acc: 0.5996 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00250: ReduceLROnPlateau reducing learning rate to 6.063872605795482e-16.\n",
            "\n",
            "Epoch 00250: val_loss did not improve from 1.21309\n",
            "Epoch 251/500\n",
            "57418/57418 [==============================] - 13s 223us/step - loss: 1.0590 - acc: 0.5984 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00251: val_loss did not improve from 1.21309\n",
            "Epoch 252/500\n",
            " 1344/57418 [..............................] - ETA: 12s - loss: 1.0739 - acc: 0.6079"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 221us/step - loss: 1.0592 - acc: 0.6014 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00252: val_loss did not improve from 1.21309\n",
            "Epoch 253/500\n",
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0578 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00253: ReduceLROnPlateau reducing learning rate to 5.45748558344395e-16.\n",
            "\n",
            "Epoch 00253: val_loss did not improve from 1.21309\n",
            "Epoch 254/500\n",
            " 8512/57418 [===>..........................] - ETA: 10s - loss: 1.0684 - acc: 0.5943"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "57418/57418 [==============================] - 13s 220us/step - loss: 1.0615 - acc: 0.5982 - val_loss: 1.2250 - val_acc: 0.5425\n",
            "\n",
            "Epoch 00254: val_loss did not improve from 1.21309\n",
            "Epoch 255/500\n",
            "23296/57418 [===========>..................] - ETA: 7s - loss: 1.0686 - acc: 0.5944"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2z5Xq5RgyJgn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.save_weights(\"drive/face_expr_model2.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBUGjVtXyUDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "23394b7d-473a-430c-f678-1aa83338ba7e"
      },
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test, Y_test, batch_size=batch_size)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3589/3589 [==============================] - 0s 68us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2448785724530946, 0.5402619114291471]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "RlI2rjGdI85C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model3 - My own"
      ]
    },
    {
      "metadata": {
        "id": "JQhWxjYBAiaG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Model3():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
        "  model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfA9kpRUNSit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3=Model3()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R4NakEqqxw1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "gen = ImageDataGenerator()\n",
        "train_generator = gen.flow(X_train, Y_train, batch_size=batch_size)\n",
        " \n",
        "model3.compile(loss='categorical_crossentropy'\n",
        ", optimizer=Adam()\n",
        ", metrics=['accuracy']\n",
        ")\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d3Dfmh5nxa5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model3.load_weights(\"drive/face_expr_model3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zuvOjzW8JRxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10455
        },
        "outputId": "160745e3-eb32-4dcc-9954-60d8e1b7c7d2"
      },
      "cell_type": "code",
      "source": [
        "model3.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=300)\n"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "64/64 [==============================] - 5s 75ms/step - loss: 1.8311 - acc: 0.2417\n",
            "Epoch 2/300\n",
            "64/64 [==============================] - 3s 40ms/step - loss: 1.8172 - acc: 0.2549\n",
            "Epoch 3/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.8183 - acc: 0.2466\n",
            "Epoch 4/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.8146 - acc: 0.2502\n",
            "Epoch 5/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.8051 - acc: 0.2573\n",
            "Epoch 6/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.8061 - acc: 0.2581\n",
            "Epoch 7/300\n",
            "64/64 [==============================] - 3s 40ms/step - loss: 1.8217 - acc: 0.2429\n",
            "Epoch 8/300\n",
            "31/64 [=============>................] - ETA: 1s - loss: 1.8144 - acc: 0.2414"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 3s 40ms/step - loss: 1.8065 - acc: 0.2549\n",
            "Epoch 9/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.8134 - acc: 0.2476\n",
            "Epoch 10/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.8110 - acc: 0.2527\n",
            "Epoch 11/300\n",
            "64/64 [==============================] - 3s 40ms/step - loss: 1.8095 - acc: 0.2541\n",
            "Epoch 12/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.8180 - acc: 0.2451\n",
            "Epoch 13/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.8170 - acc: 0.2507\n",
            "Epoch 14/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.8112 - acc: 0.2524\n",
            "Epoch 15/300\n",
            "41/64 [==================>...........] - ETA: 0s - loss: 1.8104 - acc: 0.2588"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.8101 - acc: 0.2556\n",
            "Epoch 16/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.8027 - acc: 0.2654\n",
            "Epoch 17/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.8196 - acc: 0.2407\n",
            "Epoch 18/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.8129 - acc: 0.2495\n",
            "Epoch 19/300\n",
            "64/64 [==============================] - 3s 40ms/step - loss: 1.8173 - acc: 0.2463\n",
            "Epoch 20/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.7908 - acc: 0.2607\n",
            "Epoch 21/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.8002 - acc: 0.2427\n",
            "Epoch 22/300\n",
            "41/64 [==================>...........] - ETA: 0s - loss: 1.8114 - acc: 0.2534"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.8050 - acc: 0.2546\n",
            "Epoch 23/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.7799 - acc: 0.2668\n",
            "Epoch 24/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.7382 - acc: 0.2920\n",
            "Epoch 25/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.7009 - acc: 0.2919\n",
            "Epoch 26/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.7090 - acc: 0.3013\n",
            "Epoch 27/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.6949 - acc: 0.3091\n",
            "Epoch 28/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.6770 - acc: 0.3342\n",
            "Epoch 29/300\n",
            "38/64 [================>.............] - ETA: 1s - loss: 1.6674 - acc: 0.3302"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.6667 - acc: 0.3254\n",
            "Epoch 30/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.6472 - acc: 0.3442\n",
            "Epoch 31/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.6242 - acc: 0.3560\n",
            "Epoch 32/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.6326 - acc: 0.3501\n",
            "Epoch 33/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.6161 - acc: 0.3564\n",
            "Epoch 34/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.5891 - acc: 0.3643\n",
            "Epoch 35/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.5898 - acc: 0.3713\n",
            "Epoch 36/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.5893 - acc: 0.3654"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.5871 - acc: 0.3650\n",
            "Epoch 37/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.5714 - acc: 0.3811\n",
            "Epoch 38/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.5732 - acc: 0.3774\n",
            "Epoch 39/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.5484 - acc: 0.3813\n",
            "Epoch 40/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.5330 - acc: 0.3889\n",
            "Epoch 41/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.5870 - acc: 0.3677\n",
            "Epoch 42/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.5322 - acc: 0.3950\n",
            "Epoch 43/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.5152 - acc: 0.4123"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.5258 - acc: 0.4170\n",
            "Epoch 44/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.5222 - acc: 0.4114\n",
            "Epoch 45/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.5099 - acc: 0.4167\n",
            "Epoch 46/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.5027 - acc: 0.4163\n",
            "Epoch 47/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.5067 - acc: 0.4111\n",
            "Epoch 48/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4629 - acc: 0.4424\n",
            "Epoch 49/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.4737 - acc: 0.4231\n",
            "Epoch 50/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.4962 - acc: 0.4226"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.4811 - acc: 0.4302\n",
            "Epoch 51/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4917 - acc: 0.4106\n",
            "Epoch 52/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4517 - acc: 0.4309\n",
            "Epoch 53/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4539 - acc: 0.4319\n",
            "Epoch 54/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4336 - acc: 0.4441\n",
            "Epoch 55/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4435 - acc: 0.4426\n",
            "Epoch 56/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.4431 - acc: 0.4421\n",
            "Epoch 57/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.4499 - acc: 0.4415"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4429 - acc: 0.4441\n",
            "Epoch 58/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3935 - acc: 0.4622\n",
            "Epoch 59/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4140 - acc: 0.4465\n",
            "Epoch 60/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.4407 - acc: 0.4395\n",
            "Epoch 61/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4129 - acc: 0.4514\n",
            "Epoch 62/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4133 - acc: 0.4453\n",
            "Epoch 63/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4140 - acc: 0.4490\n",
            "Epoch 64/300\n",
            "37/64 [================>.............] - ETA: 1s - loss: 1.3742 - acc: 0.4721"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3823 - acc: 0.4685\n",
            "Epoch 65/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.4182 - acc: 0.4473\n",
            "Epoch 66/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.4044 - acc: 0.4639\n",
            "Epoch 67/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3782 - acc: 0.4702\n",
            "Epoch 68/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.4047 - acc: 0.4551\n",
            "Epoch 69/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3673 - acc: 0.4670\n",
            "Epoch 70/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.4154 - acc: 0.4594\n",
            "Epoch 71/300\n",
            "41/64 [==================>...........] - ETA: 0s - loss: 1.3742 - acc: 0.4638"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3819 - acc: 0.4688\n",
            "Epoch 72/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3632 - acc: 0.4739\n",
            "Epoch 73/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3745 - acc: 0.4763\n",
            "Epoch 74/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3660 - acc: 0.4795\n",
            "Epoch 75/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3701 - acc: 0.4749\n",
            "Epoch 76/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3598 - acc: 0.4746\n",
            "Epoch 77/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3710 - acc: 0.4683\n",
            "Epoch 78/300\n",
            "41/64 [==================>...........] - ETA: 0s - loss: 1.3346 - acc: 0.5011"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3539 - acc: 0.4805\n",
            "Epoch 79/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3684 - acc: 0.4734\n",
            "Epoch 80/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3846 - acc: 0.4629\n",
            "Epoch 81/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3366 - acc: 0.4832\n",
            "Epoch 82/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3812 - acc: 0.4668\n",
            "Epoch 83/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3661 - acc: 0.4661\n",
            "Epoch 84/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3361 - acc: 0.4854\n",
            "Epoch 85/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.3425 - acc: 0.4692"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3656 - acc: 0.4626\n",
            "Epoch 86/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3187 - acc: 0.4985\n",
            "Epoch 87/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3648 - acc: 0.4705\n",
            "Epoch 88/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3558 - acc: 0.4724\n",
            "Epoch 89/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3234 - acc: 0.4868\n",
            "Epoch 90/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3489 - acc: 0.4807\n",
            "Epoch 91/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3215 - acc: 0.4944\n",
            "Epoch 92/300\n",
            "41/64 [==================>...........] - ETA: 0s - loss: 1.3584 - acc: 0.4787"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3397 - acc: 0.4829\n",
            "Epoch 93/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2993 - acc: 0.5088\n",
            "Epoch 94/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3232 - acc: 0.4841\n",
            "Epoch 95/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3462 - acc: 0.4922\n",
            "Epoch 96/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3181 - acc: 0.5000\n",
            "Epoch 97/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3380 - acc: 0.4795\n",
            "Epoch 98/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3433 - acc: 0.4871\n",
            "Epoch 99/300\n",
            "43/64 [===================>..........] - ETA: 0s - loss: 1.2957 - acc: 0.5000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3049 - acc: 0.4929\n",
            "Epoch 100/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3292 - acc: 0.4971\n",
            "Epoch 101/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3029 - acc: 0.4946\n",
            "Epoch 102/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3265 - acc: 0.4863\n",
            "Epoch 103/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3030 - acc: 0.5088\n",
            "Epoch 104/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2984 - acc: 0.4990\n",
            "Epoch 105/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3083 - acc: 0.5000\n",
            "Epoch 106/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.2911 - acc: 0.5152"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3044 - acc: 0.5060\n",
            "Epoch 107/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3107 - acc: 0.4932\n",
            "Epoch 108/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2999 - acc: 0.5085\n",
            "Epoch 109/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3112 - acc: 0.4983\n",
            "Epoch 110/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3069 - acc: 0.4919\n",
            "Epoch 111/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3128 - acc: 0.4995\n",
            "Epoch 112/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.2969 - acc: 0.4983\n",
            "Epoch 113/300\n",
            "37/64 [================>.............] - ETA: 1s - loss: 1.3034 - acc: 0.4992"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2915 - acc: 0.5105\n",
            "Epoch 114/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2735 - acc: 0.5115\n",
            "Epoch 115/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3021 - acc: 0.5061\n",
            "Epoch 116/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.2792 - acc: 0.5149\n",
            "Epoch 117/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2567 - acc: 0.5205\n",
            "Epoch 118/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3099 - acc: 0.5046\n",
            "Epoch 119/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2848 - acc: 0.5103\n",
            "Epoch 120/300\n",
            "34/64 [==============>...............] - ETA: 1s - loss: 1.2967 - acc: 0.4995"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2848 - acc: 0.5066\n",
            "Epoch 121/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3048 - acc: 0.4934\n",
            "Epoch 122/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2884 - acc: 0.5037\n",
            "Epoch 123/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2731 - acc: 0.5044\n",
            "Epoch 124/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2858 - acc: 0.5032\n",
            "Epoch 125/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.2732 - acc: 0.5159\n",
            "Epoch 126/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2713 - acc: 0.5093\n",
            "Epoch 127/300\n",
            "37/64 [================>.............] - ETA: 1s - loss: 1.3092 - acc: 0.5034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2911 - acc: 0.5095\n",
            "Epoch 128/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2406 - acc: 0.5195\n",
            "Epoch 129/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2591 - acc: 0.5186\n",
            "Epoch 130/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2755 - acc: 0.5122\n",
            "Epoch 131/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2495 - acc: 0.5225\n",
            "Epoch 132/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.2686 - acc: 0.5188\n",
            "Epoch 133/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.2418 - acc: 0.5266\n",
            "Epoch 134/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.2696 - acc: 0.5152"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2706 - acc: 0.5149\n",
            "Epoch 135/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2536 - acc: 0.5166\n",
            "Epoch 136/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2573 - acc: 0.5125\n",
            "Epoch 137/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.3119 - acc: 0.5015\n",
            "Epoch 138/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2627 - acc: 0.5222\n",
            "Epoch 139/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2699 - acc: 0.5061\n",
            "Epoch 140/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.3008 - acc: 0.5061\n",
            "Epoch 141/300\n",
            "37/64 [================>.............] - ETA: 1s - loss: 1.2716 - acc: 0.5114"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2524 - acc: 0.5171\n",
            "Epoch 142/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2467 - acc: 0.5205\n",
            "Epoch 143/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2535 - acc: 0.5204\n",
            "Epoch 144/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2670 - acc: 0.5134\n",
            "Epoch 145/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2298 - acc: 0.5220\n",
            "Epoch 146/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2440 - acc: 0.5234\n",
            "Epoch 147/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2318 - acc: 0.5293\n",
            "Epoch 148/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.2676 - acc: 0.5096"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2578 - acc: 0.5115\n",
            "Epoch 149/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2475 - acc: 0.5168\n",
            "Epoch 150/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2410 - acc: 0.5259\n",
            "Epoch 151/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2462 - acc: 0.5220\n",
            "Epoch 152/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2313 - acc: 0.5251\n",
            "Epoch 153/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2624 - acc: 0.5200\n",
            "Epoch 154/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2536 - acc: 0.5281\n",
            "Epoch 155/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.2660 - acc: 0.5107"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2501 - acc: 0.5227\n",
            "Epoch 156/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2349 - acc: 0.5186\n",
            "Epoch 157/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.1863 - acc: 0.5444\n",
            "Epoch 158/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2421 - acc: 0.5227\n",
            "Epoch 159/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2272 - acc: 0.5297\n",
            "Epoch 160/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2673 - acc: 0.5161\n",
            "Epoch 161/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2581 - acc: 0.5129\n",
            "Epoch 162/300\n",
            "37/64 [================>.............] - ETA: 1s - loss: 1.2415 - acc: 0.5355"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2230 - acc: 0.5403\n",
            "Epoch 163/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2084 - acc: 0.5378\n",
            "Epoch 164/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2324 - acc: 0.5339\n",
            "Epoch 165/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2246 - acc: 0.5374\n",
            "Epoch 166/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2300 - acc: 0.5342\n",
            "Epoch 167/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2429 - acc: 0.5188\n",
            "Epoch 168/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2422 - acc: 0.5256\n",
            "Epoch 169/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.2350 - acc: 0.5148"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2247 - acc: 0.5205\n",
            "Epoch 170/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2075 - acc: 0.5276\n",
            "Epoch 171/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2329 - acc: 0.5293\n",
            "Epoch 172/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2082 - acc: 0.5435\n",
            "Epoch 173/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2108 - acc: 0.5425\n",
            "Epoch 174/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.1917 - acc: 0.5334\n",
            "Epoch 175/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2052 - acc: 0.5371\n",
            "Epoch 176/300\n",
            "37/64 [================>.............] - ETA: 1s - loss: 1.2185 - acc: 0.5312"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2191 - acc: 0.5334\n",
            "Epoch 177/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2346 - acc: 0.5254\n",
            "Epoch 178/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2167 - acc: 0.5315\n",
            "Epoch 179/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2255 - acc: 0.5359\n",
            "Epoch 180/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2243 - acc: 0.5337\n",
            "Epoch 181/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2323 - acc: 0.5288\n",
            "Epoch 182/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2070 - acc: 0.5317\n",
            "Epoch 183/300\n",
            "37/64 [================>.............] - ETA: 1s - loss: 1.1830 - acc: 0.5469"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2043 - acc: 0.5356\n",
            "Epoch 184/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.1816 - acc: 0.5439\n",
            "Epoch 185/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1859 - acc: 0.5532\n",
            "Epoch 186/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.1869 - acc: 0.5500\n",
            "Epoch 187/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1813 - acc: 0.5462\n",
            "Epoch 188/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2083 - acc: 0.5408\n",
            "Epoch 189/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.2294 - acc: 0.5227\n",
            "Epoch 190/300\n",
            "31/64 [=============>................] - ETA: 1s - loss: 1.2136 - acc: 0.5474"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2161 - acc: 0.5469\n",
            "Epoch 191/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2396 - acc: 0.5298\n",
            "Epoch 192/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1996 - acc: 0.5464\n",
            "Epoch 193/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1809 - acc: 0.5427\n",
            "Epoch 194/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1818 - acc: 0.5476\n",
            "Epoch 195/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.2297 - acc: 0.5229\n",
            "Epoch 196/300\n",
            "64/64 [==============================] - 3s 39ms/step - loss: 1.1937 - acc: 0.5435\n",
            "Epoch 197/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.2602 - acc: 0.5174"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2074 - acc: 0.5354\n",
            "Epoch 198/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1904 - acc: 0.5454\n",
            "Epoch 199/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1853 - acc: 0.5557\n",
            "Epoch 200/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1844 - acc: 0.5568\n",
            "Epoch 201/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2048 - acc: 0.5432\n",
            "Epoch 202/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1986 - acc: 0.5466\n",
            "Epoch 203/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.1781 - acc: 0.5508\n",
            "Epoch 204/300\n",
            "39/64 [=================>............] - ETA: 0s - loss: 1.1790 - acc: 0.5497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1915 - acc: 0.5398\n",
            "Epoch 205/300\n",
            "64/64 [==============================] - 2s 39ms/step - loss: 1.1951 - acc: 0.5461\n",
            "Epoch 206/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1919 - acc: 0.5454\n",
            "Epoch 207/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1847 - acc: 0.5486\n",
            "Epoch 208/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2133 - acc: 0.5398\n",
            "Epoch 209/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1785 - acc: 0.5374\n",
            "Epoch 210/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.2031 - acc: 0.5549\n",
            "Epoch 211/300\n",
            "37/64 [================>.............] - ETA: 1s - loss: 1.1809 - acc: 0.5443"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1725 - acc: 0.5510\n",
            "Epoch 212/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1577 - acc: 0.5537\n",
            "Epoch 213/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1897 - acc: 0.5471\n",
            "Epoch 214/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1811 - acc: 0.5447\n",
            "Epoch 215/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1946 - acc: 0.5439\n",
            "Epoch 216/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1792 - acc: 0.5513\n",
            "Epoch 217/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1619 - acc: 0.5627\n",
            "Epoch 218/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.1698 - acc: 0.5616"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1846 - acc: 0.5522\n",
            "Epoch 219/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1691 - acc: 0.5513\n",
            "Epoch 220/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1918 - acc: 0.5509\n",
            "Epoch 221/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1750 - acc: 0.5537\n",
            "Epoch 222/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1709 - acc: 0.5586\n",
            "Epoch 223/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1914 - acc: 0.5525\n",
            "Epoch 224/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1898 - acc: 0.5449\n",
            "Epoch 225/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.1884 - acc: 0.5433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 36ms/step - loss: 1.1804 - acc: 0.5483\n",
            "Epoch 226/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1169 - acc: 0.5767\n",
            "Epoch 227/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1704 - acc: 0.5505\n",
            "Epoch 228/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1483 - acc: 0.5613\n",
            "Epoch 229/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1531 - acc: 0.5576\n",
            "Epoch 230/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1629 - acc: 0.5527\n",
            "Epoch 231/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1652 - acc: 0.5559\n",
            "Epoch 232/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.1651 - acc: 0.5594"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1552 - acc: 0.5623\n",
            "Epoch 233/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1780 - acc: 0.5469\n",
            "Epoch 234/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1855 - acc: 0.5400\n",
            "Epoch 235/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1950 - acc: 0.5449\n",
            "Epoch 236/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1730 - acc: 0.5479\n",
            "Epoch 237/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1576 - acc: 0.5544\n",
            "Epoch 238/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1599 - acc: 0.5481\n",
            "Epoch 239/300\n",
            "37/64 [================>.............] - ETA: 0s - loss: 1.1775 - acc: 0.5439"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1761 - acc: 0.5403\n",
            "Epoch 240/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1104 - acc: 0.5828\n",
            "Epoch 241/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1335 - acc: 0.5720\n",
            "Epoch 242/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1856 - acc: 0.5435\n",
            "Epoch 243/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1487 - acc: 0.5547\n",
            "Epoch 244/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1431 - acc: 0.5703\n",
            "Epoch 245/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1806 - acc: 0.5376\n",
            "Epoch 246/300\n",
            "37/64 [================>.............] - ETA: 0s - loss: 1.1741 - acc: 0.5424"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1588 - acc: 0.5549\n",
            "Epoch 247/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1394 - acc: 0.5708\n",
            "Epoch 248/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1629 - acc: 0.5544\n",
            "Epoch 249/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1651 - acc: 0.5588\n",
            "Epoch 250/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1386 - acc: 0.5747\n",
            "Epoch 251/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1591 - acc: 0.5566\n",
            "Epoch 252/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1457 - acc: 0.5591\n",
            "Epoch 253/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.1652 - acc: 0.5527"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1533 - acc: 0.5603\n",
            "Epoch 254/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1363 - acc: 0.5642\n",
            "Epoch 255/300\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 1.1290 - acc: 0.5696\n",
            "Epoch 256/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1481 - acc: 0.5635\n",
            "Epoch 257/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1572 - acc: 0.5488\n",
            "Epoch 258/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1452 - acc: 0.5679\n",
            "Epoch 259/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1333 - acc: 0.5649\n",
            "Epoch 260/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.0929 - acc: 0.5875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1170 - acc: 0.5720\n",
            "Epoch 261/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.1246 - acc: 0.5715\n",
            "Epoch 262/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1444 - acc: 0.5588\n",
            "Epoch 263/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1441 - acc: 0.5635\n",
            "Epoch 264/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1404 - acc: 0.5656\n",
            "Epoch 265/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1356 - acc: 0.5767\n",
            "Epoch 266/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1402 - acc: 0.5535\n",
            "Epoch 267/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.1474 - acc: 0.5665"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1231 - acc: 0.5732\n",
            "Epoch 268/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1205 - acc: 0.5725\n",
            "Epoch 269/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1239 - acc: 0.5723\n",
            "Epoch 270/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1168 - acc: 0.5737\n",
            "Epoch 271/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1339 - acc: 0.5618\n",
            "Epoch 272/300\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 1.1486 - acc: 0.5618\n",
            "Epoch 273/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1121 - acc: 0.5735\n",
            "Epoch 274/300\n",
            "33/64 [==============>...............] - ETA: 1s - loss: 1.1454 - acc: 0.5578"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1627 - acc: 0.5540\n",
            "Epoch 275/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1385 - acc: 0.5632\n",
            "Epoch 276/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1146 - acc: 0.5693\n",
            "Epoch 277/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1494 - acc: 0.5630\n",
            "Epoch 278/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1344 - acc: 0.5693\n",
            "Epoch 279/300\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 1.1348 - acc: 0.5642\n",
            "Epoch 280/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1154 - acc: 0.5696\n",
            "Epoch 281/300\n",
            "33/64 [==============>...............] - ETA: 1s - loss: 1.1651 - acc: 0.5545"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1454 - acc: 0.5605\n",
            "Epoch 282/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1140 - acc: 0.5791\n",
            "Epoch 283/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1002 - acc: 0.5708\n",
            "Epoch 284/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1014 - acc: 0.5833\n",
            "Epoch 285/300\n",
            "64/64 [==============================] - 2s 38ms/step - loss: 1.0906 - acc: 0.5842\n",
            "Epoch 286/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1205 - acc: 0.5681\n",
            "Epoch 287/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1171 - acc: 0.5671\n",
            "Epoch 288/300\n",
            "33/64 [==============>...............] - ETA: 1s - loss: 1.1146 - acc: 0.5748"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1091 - acc: 0.5781\n",
            "Epoch 289/300\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 1.1187 - acc: 0.5696\n",
            "Epoch 290/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1586 - acc: 0.5586\n",
            "Epoch 291/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1309 - acc: 0.5678\n",
            "Epoch 292/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1219 - acc: 0.5684\n",
            "Epoch 293/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1224 - acc: 0.5723\n",
            "Epoch 294/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1738 - acc: 0.5439\n",
            "Epoch 295/300\n",
            "35/64 [===============>..............] - ETA: 1s - loss: 1.0832 - acc: 0.5902"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1112 - acc: 0.5771\n",
            "Epoch 296/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.0713 - acc: 0.5901\n",
            "Epoch 297/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1165 - acc: 0.5791\n",
            "Epoch 298/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.0857 - acc: 0.5823\n",
            "Epoch 299/300\n",
            "64/64 [==============================] - 2s 37ms/step - loss: 1.1112 - acc: 0.5754\n",
            "Epoch 300/300\n",
            "64/64 [==============================] - 2s 36ms/step - loss: 1.1125 - acc: 0.5623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4923d67710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 334
        }
      ]
    },
    {
      "metadata": {
        "id": "qSth_XTcMwv7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " model3.save_weights(\"drive/face_expr_model3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQzCcQQWOBxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "531ede6c-9d6e-4208-882e-84b018394504"
      },
      "cell_type": "code",
      "source": [
        "model3.evaluate(X_test, Y_test, batch_size=batch_size)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3589/3589 [==============================] - 1s 202us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2636825706873076, 0.5204792421619419]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "_eoeQEgIxp35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}